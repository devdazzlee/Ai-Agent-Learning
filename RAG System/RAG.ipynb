{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MCqzFkY1coU",
        "outputId": "572f5911-704e-4ac5-c4f5-9c179e863684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function Calling\n"
          ]
        }
      ],
      "source": [
        "print(\"Function Calling\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSwnITWh5mn9",
        "outputId": "336deb35-771a-4f77-c6c9-01d56637444a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 12\n",
        "while  i < 20:\n",
        "  print(i)\n",
        "  i = i+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqV3BNX0560G",
        "outputId": "873702d8-28f5-4f70-cc98-1b9836be6131"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Image Audio Files"
      ],
      "metadata": {
        "id": "yOJ23-YS-X6F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rag System\n",
        "# R Reterival\n",
        "# A Augment ==> Set Data in Prompt\n",
        "# G Generation"
      ],
      "metadata": {
        "id": "ydfGhZVPckRQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization model according to how much data is relevant for Rag system\n",
        "\n",
        "# An embedding model is a type of machine‑learning model whose main job is to turn inputs (words, sentences, images, users, items, etc.) into fixed‑length vectors of numbers—called embeddings—that capture their essential properties and relationships.\n",
        "#  You can think of an embedding as a point in a high‑dimensional space where “similar” things end up close together.\n",
        "\n"
      ],
      "metadata": {
        "id": "13Gn29OGctyD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "\n",
        "# Splits raw text into tokens (words, subwords, or characters).\n",
        "\n",
        "# Maps each token to a unique integer ID.\n",
        "\n",
        "# Embedding model\n",
        "\n",
        "# Takes those integer IDs (or the tokens) as input.\n",
        "\n",
        "# Looks up or computes a fixed‑length real‑valued vector for each token (or aggregates them for a sentence/document).\n",
        "\n",
        "# \"unbelievable\"\n",
        "#   → [\"un\", \"##believ\", \"##able\"]\n",
        "#   → [  834,      15237,    719  ]       (tokenizer)\n",
        "#   → [0.12, –0.05, …, 0.02]              (embedding)"
      ],
      "metadata": {
        "id": "MYaIV17RsmlQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI_2oZ69Jofr",
        "outputId": "78b0fe1e-5184-4f90-a23a-3a1be858e652"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 0.0.9 requires google-generativeai<0.4.0,>=0.3.1, but you have google-generativeai 0.8.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "# from google.cloud import userdata\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyD4gRQkOAfWHix87V7Lo7fbms8OPdEJplE\")"
      ],
      "metadata": {
        "id": "IKoUI5wRJ8hl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(genai.list_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-Z-kw-97L7oI",
        "outputId": "9e020a11-7d89-4f5f-bfed-00a93f21b3d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.5-pro-exp-03-25',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini 2.5 Pro Experimental 03-25',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-pro-preview-03-25',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-03-25',\n",
              "       display_name='Gemini 2.5 Pro Preview 03-25',\n",
              "       description='Gemini 2.5 Pro Preview 03-25',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-preview-04-17',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-04-17',\n",
              "       display_name='Gemini 2.5 Flash Preview 04-17',\n",
              "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash',\n",
              "       description='Gemini 2.0 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash 001',\n",
              "       description=('Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in January of 2025.'),\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp-image-generation',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash (Image Generation) Experimental',\n",
              "       description='Gemini 2.0 Flash (Image Generation) Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite 001',\n",
              "       description='Stable version of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite',\n",
              "       description='Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview-02-05',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-pro-exp',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini 2.0 Pro Experimental',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-pro-exp-02-05',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini 2.0 Pro Experimental 02-05',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-01-21',\n",
              "       base_model_id='',\n",
              "       version='2.0-exp-01-21',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n",
              "       description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0-exp-01-21',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n",
              "       description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-2.0-flash-experimental',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='LearnLM 2.0 Flash Experimental',\n",
              "       description='LearnLM 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=32768,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-1b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 1B',\n",
              "       description='',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-4b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 4B',\n",
              "       description='',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-12b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 12B',\n",
              "       description='',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-27b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 27B',\n",
              "       description='',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-exp-03-07',\n",
              "       base_model_id='',\n",
              "       version='exp-03-07',\n",
              "       display_name='Gemini Embedding Experimental 03-07',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-exp',\n",
              "       base_model_id='',\n",
              "       version='exp-03-07',\n",
              "       display_name='Gemini Embedding Experimental',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40),\n",
              " Model(name='models/imagen-3.0-generate-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Imagen 3.0 002 model',\n",
              "       description='Vertex served Imagen 3.0 002 model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-2.0-flash-live-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 2.0 Flash 001',\n",
              "       description='Gemini 2.0 Flash 001',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['bidiGenerateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=\"What is the meaning of Life?\",\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of Single String\"\n",
        ")\n",
        "\n",
        "print(\"embedding\")\n",
        "print(result)\n",
        "print(result[\"embedding\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "inVOyr2zMkAE",
        "outputId": "56beac5a-c899-4076-b488-2d7e613928ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding\n",
            "{'embedding': [-0.0012978165, -0.0057790657, -0.018239113, -0.008663372, 0.03844243, -9.760191e-05, 0.04560358, -0.0011043422, -0.021204438, 0.007409066, -0.015003322, 0.0104793385, -0.004206538, -0.04029302, -0.016768102, -0.033133887, 0.040423766, -0.0060274424, -0.011143942, -0.034508727, -0.02062826, -0.033153936, 0.031863462, 0.016741447, -0.011101371, -0.01945125, 0.043991916, -0.05194145, -0.01741339, 0.031932093, -0.031348974, 0.020000469, -0.06810303, -0.00250949, 0.044274647, -0.0445408, 0.01864265, -0.030017985, -0.07623094, 0.0081874, 0.044017605, -0.045063727, -0.036753256, -0.040895794, 0.0031661994, 0.0150675895, -0.018128159, 0.0500001, 0.021237558, -0.12060966, 0.019002983, 0.024426237, 0.10927421, -0.019056877, -0.022559728, -0.025551481, 0.049273007, -0.0014085829, -0.014641131, -0.017922198, 0.0056922855, -0.017760905, 0.0015678755, 0.040462166, -0.0042481255, -0.030306691, -0.0038070625, 0.0396827, 0.044229154, -0.013365835, 0.014041138, -0.008520128, 0.021345481, 0.0096997, -0.005531619, -0.075344, 0.008022202, 0.033113692, 0.004399037, -0.0006637361, 0.008270688, -0.01757923, -0.029401714, -0.025137538, -0.07121908, 0.029888567, -0.05513053, -0.0062904446, -0.030267654, 0.03136202, 0.013907977, -0.030750275, 0.005813021, -0.06575425, -0.008639827, 0.056204524, -0.025052926, -0.019473033, 0.03758343, 0.011552422, 0.017340738, -0.018539228, -0.06507455, 0.038803775, 0.005787578, -0.011577194, 0.038015492, 0.0829802, 0.034571752, 0.074468926, 0.0037036138, -0.043686595, -0.008552551, 0.023052357, 0.027299669, -0.0007890809, 0.01429942, 0.018239615, 0.022505539, -0.0005153612, 0.020833842, 0.03402894, 0.11514626, -0.031077359, 0.0045895604, 0.050473817, -0.018644875, 0.009355947, 0.02588398, 0.030100478, -0.0016947201, -0.04560311, 0.029463256, 0.028654605, 0.07524761, 0.11992303, 0.012260244, 0.024006872, 0.027007345, 0.031257596, -0.018684404, 0.066650346, 0.051959906, 0.07092391, -0.050373577, 0.022033002, -0.03651545, -0.022157354, 0.041323174, -0.035133727, -0.041860543, 0.017125992, -0.11765632, -0.0023807327, 0.068936504, 0.0077988124, -0.002939139, 0.06627687, -0.026805855, 0.01511775, 0.026938478, -0.0024847768, -0.022694232, 0.04433626, 0.045631453, 0.0012161836, -0.019679448, -0.056319963, 0.002538509, 0.025128571, -0.0033270672, 0.0471879, -0.059639286, -0.039755415, -0.011060186, -0.060140047, -0.020150112, 0.016930772, -0.012372823, 0.009840986, -0.0017064747, -0.034628037, -0.045336645, -0.0064619533, 0.03992354, -0.011440864, 0.035453558, -0.063961744, -0.02184723, -0.011661249, -0.03226944, -0.0016327113, -0.023731168, -0.010442959, -0.010424415, -0.0063490495, 0.014565345, 0.040561818, 0.05981676, -0.016541585, -0.0031516417, 0.058389213, 0.02654352, -0.013698689, -0.0005054029, -0.015993806, 0.029051261, -0.03918811, -0.050877616, 0.043845553, -0.014923215, -0.009880877, 0.027120037, 0.04771232, 0.043398723, -0.013695877, -0.0008940597, 0.009522579, 0.011304927, -0.043547805, 0.014918301, -0.0021034232, -0.028270885, -0.0025206862, 0.020240935, 0.030764949, -0.014176155, 0.035381325, 0.032195624, -0.027278906, -0.011380765, 0.072995275, 0.04317547, -0.02487787, 0.019759094, -0.04525277, 0.057314973, 0.05180962, -0.0004928808, 0.009246616, -0.02149454, 0.0058545195, 0.038464896, 0.039751768, -0.052941967, -0.03732239, -0.03784448, 0.055894714, -0.0019128706, 0.026013536, 0.0023175192, -0.023173247, -0.022655532, 0.072779916, -0.02390276, 0.031576242, -0.025498128, 0.00732947, -0.012280026, 0.037145473, 0.0738099, 0.027475784, 0.042517103, -0.029569361, -0.03926899, -0.03604653, 0.015474879, -0.0700849, 0.02052113, -0.00025533148, 0.0011285647, -0.004064258, 0.01307868, -0.025455404, -0.038544077, -0.0048234034, -0.031980067, 0.04692348, 0.00090778444, -0.03626308, 0.033077337, 0.019632801, -0.029374713, -0.020885002, 0.0064603905, 0.010395019, -0.046525937, -0.022462945, 0.012820945, -0.057818867, -0.0103822285, -0.018602807, -0.032777034, -0.05055544, -0.041604783, -0.007580006, -0.004643797, 0.07107344, 0.040508702, 0.008675984, -0.0221436, -0.050323904, 0.006093469, -0.08348287, 0.009637554, 0.0097655235, 0.014353882, -0.051417552, -0.041846562, 0.019680485, -0.017458346, -0.01003978, -0.035810344, 3.0991512e-05, 0.014760989, 0.025628792, -0.00413619, 0.046481315, -0.01415765, 0.05890448, -0.023248116, 0.096417524, 0.029605785, 0.018657869, -0.049216326, 0.012555726, -0.025957955, 0.06401777, 0.035246912, 0.014102936, -0.012736134, -0.05963122, -0.020099288, 0.005901233, 0.02591995, 0.06569564, -0.049033806, 0.007674448, -0.042207967, -0.025964236, 0.010772511, 0.03945343, -0.017273642, -0.049692925, 0.017631486, -0.050383683, -0.04665375, 0.014475215, 0.0832275, -0.010375306, 0.045587424, 0.053761892, -0.01137322, 0.023730092, 0.03858676, -0.039731145, 0.05605786, -0.037692416, 0.030350626, -0.014856968, -0.012281907, 0.037959732, 0.01736265, -0.039836667, 0.02701379, 0.0005624041, -0.038557593, 0.04636225, -0.0073205703, 0.0006895182, 0.011152733, -0.021122253, 0.03143914, -0.02818132, 0.026121764, -0.004437109, -0.03341277, -0.014327644, 0.056119308, -0.009605235, -0.05913816, -0.014907457, 0.032402176, 0.011468065, 0.0030128208, -0.03432372, 0.016033111, 0.033586964, -0.0030605516, 0.043235503, 0.020485267, 0.0062330137, 0.043495018, 0.014035014, 0.04008558, 0.012386331, 0.0370624, -0.021578314, 0.016841538, -0.0134941675, -0.030043043, -0.0064489436, -0.033949606, 0.0024311151, -0.015680024, -0.015189835, -0.0026111556, 0.009296004, 0.009645917, 0.0041120052, 0.0054405173, 0.009434963, -0.0069626, -0.05188063, -0.044569846, 0.00022728635, 0.022955775, -0.00161516, -0.0030939223, 0.035791237, -0.04043497, -0.009249536, 0.0012105126, -0.011462435, -0.045117293, -0.023388958, 0.036679935, -0.022559261, 0.03211389, -0.007443385, 0.07698526, -0.0028479362, 0.037577666, 0.0032554234, 0.0064285113, -0.04630667, 0.019999119, 0.031096559, -0.01042492, -0.034165822, 0.014189266, 0.008524472, 0.03982642, -0.012307999, -0.040241476, 0.02098769, -0.0013550515, -0.018042175, 0.017541947, -0.115576625, 0.018587923, -0.018249232, -0.010280455, -0.055563804, -0.044610474, -0.025118332, -0.0013098512, 0.08327138, -0.02189557, -0.03262583, -0.0036845512, -0.023785463, -0.02910916, -0.10494527, -0.0026042694, -0.010164676, 0.018847661, 0.0059391037, 0.038095612, 0.06277569, -0.0008414559, -0.02902953, 0.02953362, -0.030007267, -0.02082031, -0.03051118, -0.04852553, 0.0010297511, -0.03067935, 0.0074198144, -0.007975889, 0.015781162, 0.021984035, 0.018410593, -0.051966242, 0.0015102847, 0.016626254, 0.03519161, -0.020763488, 0.07523439, -0.009499261, -0.053897627, 0.025622105, -0.04347762, -0.0024714961, 0.015669342, -0.04136859, 0.0317957, 0.021943342, 0.025990883, -0.030000681, -0.04157024, -0.02202943, 0.0044922256, 0.09448465, -0.11869322, 0.03336812, 0.013029495, -0.027321154, -0.039741326, -0.027410053, 0.017141363, -0.007567203, 0.021533538, 0.09942571, -0.0249417, 0.0048186476, -0.006500673, 0.027452655, -0.003210179, 0.08664042, -0.00093190797, -0.10329442, -0.038249046, -0.004667621, -0.003399676, 0.0453721, 0.03079189, -0.006129803, -0.0070093586, -0.07278044, 0.040788226, -0.09910187, -0.0077433526, 0.012369384, -0.024395518, -0.016188271, 0.011940514, 0.044531852, 0.0081202835, 0.019294713, -0.01946267, 0.046966095, 0.041628577, -0.0134598585, 0.002784934, 0.010538378, -0.09723573, 0.027476773, -0.007544432, -0.0567123, 0.03800113, 0.0071073296, -0.027665833, 0.024973443, 0.028754028, -0.029480977, 0.027862215, 0.028979592, -0.037872635, -0.0020229653, 0.0008561855, -0.017251251, -0.00021646947, 0.06937088, 0.0038350003, -0.03477719, -0.0048138057, 0.06170126, -0.052593064, -0.020145332, 0.048848834, 0.047545895, -0.0087441215, 0.0144988885, 0.010857363, -0.014169798, -0.026827097, -0.041658882, -0.010186621, 0.045631297, -0.006906432, 0.013213517, 0.035637617, 0.013926411, -0.029778246, 0.09966252, 0.041688003, 0.016224325, 0.039778735, -0.038647357, 0.02355176, 0.02129205, -0.016734626, -0.0029843922, -0.01920314, 0.008801097, -0.004214766, -0.022292936, -0.029831454, 0.00993429, -0.049194764, 0.07184709, -0.028113432, 0.03206641, 0.0583509, -0.014758096, -0.017781818, -0.008365404, 0.058709014, -0.04891678, -0.03258236, -0.029275388, 0.02009885, 0.018833613, -0.07770287, 0.048258513, -0.0077042836, -0.036820732, -0.038361613, 0.0028261652, -0.012993257, -0.025365027, 0.047573734, 0.0037484441, 0.007292934, -0.014527762, -0.02683241, 0.04644392, -0.01343159, 0.045098253, 0.036601502, 0.010193205, 0.04926676, -0.019375581, 0.020326884, 0.007739847, -0.008395175, 0.05603638, 0.018783996, -0.06521221, -0.0050550113, -0.04282045, -0.002098509, -0.0134453615, 0.10102847, 0.006451811, -0.077263385, -0.0074810944, 0.00037731536, -0.023868807, 0.012236815, 0.04170901, -0.051183775, -0.01978286, 0.007335154, 0.0067427824, -0.0108187515, -0.0200019, 0.01657198, -0.018816344, -0.02700997, 0.017256398, -0.012674229, 0.0052351453, -0.03915623, -0.039800093, -0.028409762, -0.036332183, -0.0015814791, -0.06474003, -0.009227213, 0.052128837, -0.015170744, 0.010567299, 0.023498695, -0.07726439, 0.045509625, -0.013340082, 0.0032893114, 0.021727625, 0.010224659, -0.012392039, -0.0016127112, 0.020425582, 0.029691415, -0.0013970197, -0.014451841, -0.043076318, -0.027669711, -0.008848243, 0.011545315, -0.04396795, 0.017098684, 0.056374736, 0.0082513355, -0.00360949, 0.031770058, 0.037843302, -0.009232721, 0.0043272367, -0.0255598, -0.06281528, 0.031246185, -0.043009646, 0.028081352, 0.00066087075, 0.009188045, 0.060821816, 0.03174019, 0.026162658, -0.03701682, -0.011215332, 0.02924682, 0.019487422, -0.061657246, -0.016124152, 0.010955976, -0.03503634, 0.051719286, 0.05304428, -0.007221316, -0.005848734, -0.05837853, -0.071146846, 0.036596607, -0.03563265, -0.006271164, -0.054606337, -0.041802343, 0.05242924, -0.035856377, -0.0016969347, 0.034027074, -0.039773956, 0.07812282, 0.024921553, 0.06605836, 0.009659947, -0.07702172, -0.0029180245, -0.019732205, 0.039790455, 0.1090021, -0.037498407, -0.06831163, 0.032755136, -0.03206784, 0.05053706, -0.026113192, -0.054647896, -0.07849343, 0.0005509374, -0.054805305, 0.034038693, -0.011445047, -0.021863936, 0.00273053, 0.003958203, 0.024815798, -0.053787798, -0.012619915, -0.011286344, -0.009354745, 0.026534548, 0.026608685, 0.0336859, 0.019487835]}\n",
            "[-0.0012978165, -0.0057790657, -0.018239113, -0.008663372, 0.03844243, -9.760191e-05, 0.04560358, -0.0011043422, -0.021204438, 0.007409066, -0.015003322, 0.0104793385, -0.004206538, -0.04029302, -0.016768102, -0.033133887, 0.040423766, -0.0060274424, -0.011143942, -0.034508727, -0.02062826, -0.033153936, 0.031863462, 0.016741447, -0.011101371, -0.01945125, 0.043991916, -0.05194145, -0.01741339, 0.031932093, -0.031348974, 0.020000469, -0.06810303, -0.00250949, 0.044274647, -0.0445408, 0.01864265, -0.030017985, -0.07623094, 0.0081874, 0.044017605, -0.045063727, -0.036753256, -0.040895794, 0.0031661994, 0.0150675895, -0.018128159, 0.0500001, 0.021237558, -0.12060966, 0.019002983, 0.024426237, 0.10927421, -0.019056877, -0.022559728, -0.025551481, 0.049273007, -0.0014085829, -0.014641131, -0.017922198, 0.0056922855, -0.017760905, 0.0015678755, 0.040462166, -0.0042481255, -0.030306691, -0.0038070625, 0.0396827, 0.044229154, -0.013365835, 0.014041138, -0.008520128, 0.021345481, 0.0096997, -0.005531619, -0.075344, 0.008022202, 0.033113692, 0.004399037, -0.0006637361, 0.008270688, -0.01757923, -0.029401714, -0.025137538, -0.07121908, 0.029888567, -0.05513053, -0.0062904446, -0.030267654, 0.03136202, 0.013907977, -0.030750275, 0.005813021, -0.06575425, -0.008639827, 0.056204524, -0.025052926, -0.019473033, 0.03758343, 0.011552422, 0.017340738, -0.018539228, -0.06507455, 0.038803775, 0.005787578, -0.011577194, 0.038015492, 0.0829802, 0.034571752, 0.074468926, 0.0037036138, -0.043686595, -0.008552551, 0.023052357, 0.027299669, -0.0007890809, 0.01429942, 0.018239615, 0.022505539, -0.0005153612, 0.020833842, 0.03402894, 0.11514626, -0.031077359, 0.0045895604, 0.050473817, -0.018644875, 0.009355947, 0.02588398, 0.030100478, -0.0016947201, -0.04560311, 0.029463256, 0.028654605, 0.07524761, 0.11992303, 0.012260244, 0.024006872, 0.027007345, 0.031257596, -0.018684404, 0.066650346, 0.051959906, 0.07092391, -0.050373577, 0.022033002, -0.03651545, -0.022157354, 0.041323174, -0.035133727, -0.041860543, 0.017125992, -0.11765632, -0.0023807327, 0.068936504, 0.0077988124, -0.002939139, 0.06627687, -0.026805855, 0.01511775, 0.026938478, -0.0024847768, -0.022694232, 0.04433626, 0.045631453, 0.0012161836, -0.019679448, -0.056319963, 0.002538509, 0.025128571, -0.0033270672, 0.0471879, -0.059639286, -0.039755415, -0.011060186, -0.060140047, -0.020150112, 0.016930772, -0.012372823, 0.009840986, -0.0017064747, -0.034628037, -0.045336645, -0.0064619533, 0.03992354, -0.011440864, 0.035453558, -0.063961744, -0.02184723, -0.011661249, -0.03226944, -0.0016327113, -0.023731168, -0.010442959, -0.010424415, -0.0063490495, 0.014565345, 0.040561818, 0.05981676, -0.016541585, -0.0031516417, 0.058389213, 0.02654352, -0.013698689, -0.0005054029, -0.015993806, 0.029051261, -0.03918811, -0.050877616, 0.043845553, -0.014923215, -0.009880877, 0.027120037, 0.04771232, 0.043398723, -0.013695877, -0.0008940597, 0.009522579, 0.011304927, -0.043547805, 0.014918301, -0.0021034232, -0.028270885, -0.0025206862, 0.020240935, 0.030764949, -0.014176155, 0.035381325, 0.032195624, -0.027278906, -0.011380765, 0.072995275, 0.04317547, -0.02487787, 0.019759094, -0.04525277, 0.057314973, 0.05180962, -0.0004928808, 0.009246616, -0.02149454, 0.0058545195, 0.038464896, 0.039751768, -0.052941967, -0.03732239, -0.03784448, 0.055894714, -0.0019128706, 0.026013536, 0.0023175192, -0.023173247, -0.022655532, 0.072779916, -0.02390276, 0.031576242, -0.025498128, 0.00732947, -0.012280026, 0.037145473, 0.0738099, 0.027475784, 0.042517103, -0.029569361, -0.03926899, -0.03604653, 0.015474879, -0.0700849, 0.02052113, -0.00025533148, 0.0011285647, -0.004064258, 0.01307868, -0.025455404, -0.038544077, -0.0048234034, -0.031980067, 0.04692348, 0.00090778444, -0.03626308, 0.033077337, 0.019632801, -0.029374713, -0.020885002, 0.0064603905, 0.010395019, -0.046525937, -0.022462945, 0.012820945, -0.057818867, -0.0103822285, -0.018602807, -0.032777034, -0.05055544, -0.041604783, -0.007580006, -0.004643797, 0.07107344, 0.040508702, 0.008675984, -0.0221436, -0.050323904, 0.006093469, -0.08348287, 0.009637554, 0.0097655235, 0.014353882, -0.051417552, -0.041846562, 0.019680485, -0.017458346, -0.01003978, -0.035810344, 3.0991512e-05, 0.014760989, 0.025628792, -0.00413619, 0.046481315, -0.01415765, 0.05890448, -0.023248116, 0.096417524, 0.029605785, 0.018657869, -0.049216326, 0.012555726, -0.025957955, 0.06401777, 0.035246912, 0.014102936, -0.012736134, -0.05963122, -0.020099288, 0.005901233, 0.02591995, 0.06569564, -0.049033806, 0.007674448, -0.042207967, -0.025964236, 0.010772511, 0.03945343, -0.017273642, -0.049692925, 0.017631486, -0.050383683, -0.04665375, 0.014475215, 0.0832275, -0.010375306, 0.045587424, 0.053761892, -0.01137322, 0.023730092, 0.03858676, -0.039731145, 0.05605786, -0.037692416, 0.030350626, -0.014856968, -0.012281907, 0.037959732, 0.01736265, -0.039836667, 0.02701379, 0.0005624041, -0.038557593, 0.04636225, -0.0073205703, 0.0006895182, 0.011152733, -0.021122253, 0.03143914, -0.02818132, 0.026121764, -0.004437109, -0.03341277, -0.014327644, 0.056119308, -0.009605235, -0.05913816, -0.014907457, 0.032402176, 0.011468065, 0.0030128208, -0.03432372, 0.016033111, 0.033586964, -0.0030605516, 0.043235503, 0.020485267, 0.0062330137, 0.043495018, 0.014035014, 0.04008558, 0.012386331, 0.0370624, -0.021578314, 0.016841538, -0.0134941675, -0.030043043, -0.0064489436, -0.033949606, 0.0024311151, -0.015680024, -0.015189835, -0.0026111556, 0.009296004, 0.009645917, 0.0041120052, 0.0054405173, 0.009434963, -0.0069626, -0.05188063, -0.044569846, 0.00022728635, 0.022955775, -0.00161516, -0.0030939223, 0.035791237, -0.04043497, -0.009249536, 0.0012105126, -0.011462435, -0.045117293, -0.023388958, 0.036679935, -0.022559261, 0.03211389, -0.007443385, 0.07698526, -0.0028479362, 0.037577666, 0.0032554234, 0.0064285113, -0.04630667, 0.019999119, 0.031096559, -0.01042492, -0.034165822, 0.014189266, 0.008524472, 0.03982642, -0.012307999, -0.040241476, 0.02098769, -0.0013550515, -0.018042175, 0.017541947, -0.115576625, 0.018587923, -0.018249232, -0.010280455, -0.055563804, -0.044610474, -0.025118332, -0.0013098512, 0.08327138, -0.02189557, -0.03262583, -0.0036845512, -0.023785463, -0.02910916, -0.10494527, -0.0026042694, -0.010164676, 0.018847661, 0.0059391037, 0.038095612, 0.06277569, -0.0008414559, -0.02902953, 0.02953362, -0.030007267, -0.02082031, -0.03051118, -0.04852553, 0.0010297511, -0.03067935, 0.0074198144, -0.007975889, 0.015781162, 0.021984035, 0.018410593, -0.051966242, 0.0015102847, 0.016626254, 0.03519161, -0.020763488, 0.07523439, -0.009499261, -0.053897627, 0.025622105, -0.04347762, -0.0024714961, 0.015669342, -0.04136859, 0.0317957, 0.021943342, 0.025990883, -0.030000681, -0.04157024, -0.02202943, 0.0044922256, 0.09448465, -0.11869322, 0.03336812, 0.013029495, -0.027321154, -0.039741326, -0.027410053, 0.017141363, -0.007567203, 0.021533538, 0.09942571, -0.0249417, 0.0048186476, -0.006500673, 0.027452655, -0.003210179, 0.08664042, -0.00093190797, -0.10329442, -0.038249046, -0.004667621, -0.003399676, 0.0453721, 0.03079189, -0.006129803, -0.0070093586, -0.07278044, 0.040788226, -0.09910187, -0.0077433526, 0.012369384, -0.024395518, -0.016188271, 0.011940514, 0.044531852, 0.0081202835, 0.019294713, -0.01946267, 0.046966095, 0.041628577, -0.0134598585, 0.002784934, 0.010538378, -0.09723573, 0.027476773, -0.007544432, -0.0567123, 0.03800113, 0.0071073296, -0.027665833, 0.024973443, 0.028754028, -0.029480977, 0.027862215, 0.028979592, -0.037872635, -0.0020229653, 0.0008561855, -0.017251251, -0.00021646947, 0.06937088, 0.0038350003, -0.03477719, -0.0048138057, 0.06170126, -0.052593064, -0.020145332, 0.048848834, 0.047545895, -0.0087441215, 0.0144988885, 0.010857363, -0.014169798, -0.026827097, -0.041658882, -0.010186621, 0.045631297, -0.006906432, 0.013213517, 0.035637617, 0.013926411, -0.029778246, 0.09966252, 0.041688003, 0.016224325, 0.039778735, -0.038647357, 0.02355176, 0.02129205, -0.016734626, -0.0029843922, -0.01920314, 0.008801097, -0.004214766, -0.022292936, -0.029831454, 0.00993429, -0.049194764, 0.07184709, -0.028113432, 0.03206641, 0.0583509, -0.014758096, -0.017781818, -0.008365404, 0.058709014, -0.04891678, -0.03258236, -0.029275388, 0.02009885, 0.018833613, -0.07770287, 0.048258513, -0.0077042836, -0.036820732, -0.038361613, 0.0028261652, -0.012993257, -0.025365027, 0.047573734, 0.0037484441, 0.007292934, -0.014527762, -0.02683241, 0.04644392, -0.01343159, 0.045098253, 0.036601502, 0.010193205, 0.04926676, -0.019375581, 0.020326884, 0.007739847, -0.008395175, 0.05603638, 0.018783996, -0.06521221, -0.0050550113, -0.04282045, -0.002098509, -0.0134453615, 0.10102847, 0.006451811, -0.077263385, -0.0074810944, 0.00037731536, -0.023868807, 0.012236815, 0.04170901, -0.051183775, -0.01978286, 0.007335154, 0.0067427824, -0.0108187515, -0.0200019, 0.01657198, -0.018816344, -0.02700997, 0.017256398, -0.012674229, 0.0052351453, -0.03915623, -0.039800093, -0.028409762, -0.036332183, -0.0015814791, -0.06474003, -0.009227213, 0.052128837, -0.015170744, 0.010567299, 0.023498695, -0.07726439, 0.045509625, -0.013340082, 0.0032893114, 0.021727625, 0.010224659, -0.012392039, -0.0016127112, 0.020425582, 0.029691415, -0.0013970197, -0.014451841, -0.043076318, -0.027669711, -0.008848243, 0.011545315, -0.04396795, 0.017098684, 0.056374736, 0.0082513355, -0.00360949, 0.031770058, 0.037843302, -0.009232721, 0.0043272367, -0.0255598, -0.06281528, 0.031246185, -0.043009646, 0.028081352, 0.00066087075, 0.009188045, 0.060821816, 0.03174019, 0.026162658, -0.03701682, -0.011215332, 0.02924682, 0.019487422, -0.061657246, -0.016124152, 0.010955976, -0.03503634, 0.051719286, 0.05304428, -0.007221316, -0.005848734, -0.05837853, -0.071146846, 0.036596607, -0.03563265, -0.006271164, -0.054606337, -0.041802343, 0.05242924, -0.035856377, -0.0016969347, 0.034027074, -0.039773956, 0.07812282, 0.024921553, 0.06605836, 0.009659947, -0.07702172, -0.0029180245, -0.019732205, 0.039790455, 0.1090021, -0.037498407, -0.06831163, 0.032755136, -0.03206784, 0.05053706, -0.026113192, -0.054647896, -0.07849343, 0.0005509374, -0.054805305, 0.034038693, -0.011445047, -0.021863936, 0.00273053, 0.003958203, 0.024815798, -0.053787798, -0.012619915, -0.011286344, -0.009354745, 0.026534548, 0.026608685, 0.0336859, 0.019487835]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result[\"embedding\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smfrhXtnMuSL",
        "outputId": "a91f8746-ffa3-4d97-ceb8-df62b77dfdd1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=[\n",
        "        \"What is the meaning of Life?\",\n",
        "        \"We Love Pakistan\",\n",
        "        \"We Love USA\",\n",
        "        \"Founder of PIAIC\"\n",
        "    ],\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of Single String\"\n",
        ")\n",
        "\n",
        "for embedding in result[\"embedding\"]:\n",
        "  print(str(embedding)[:50], \"====Trimmed====\" , len(embedding) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "h2ItiIPWVJBf",
        "outputId": "346ccebe-629e-4b66-ae9d-c7e41c644e8a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.0012978165, -0.0057790657, -0.018239113, -0.00 ====Trimmed==== 768\n",
            "[0.035471346, 0.003142031, 0.013417466, -0.0393527 ====Trimmed==== 768\n",
            "[0.033062942, 0.012183793, 0.013006241, -0.0365828 ====Trimmed==== 768\n",
            "[0.048528627, 0.0050394507, 0.020653827, 0.0045722 ====Trimmed==== 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Vector Stores & Retreival using Chroma DB"
      ],
      "metadata": {
        "id": "ybK620dCW-fT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-chroma"
      ],
      "metadata": {
        "id": "t6aPWd99Wpwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4da18de-2639-4339-b4aa-40f2e13daea3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-text-splitters 0.0.2 requires langchain-core<0.3,>=0.1.28, but you have langchain-core 0.3.54 which is incompatible.\n",
            "langchain 0.1.16 requires langchain-core<0.2.0,>=0.1.42, but you have langchain-core 0.3.54 which is incompatible.\n",
            "langchain-community 0.0.32 requires langchain-core<0.2.0,>=0.1.41, but you have langchain-core 0.3.54 which is incompatible.\n",
            "langchain-google-genai 0.0.9 requires google-generativeai<0.4.0,>=0.3.1, but you have google-generativeai 0.8.5 which is incompatible.\n",
            "langchain-google-genai 0.0.9 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.3.54 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e20bu5S_W9We"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "SydjdZKLYLB0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "     Document(\n",
        "        page_content=\"Lions are majestic predators known for their strength and complex social pride structures.\",\n",
        "        metadata={\"source\": \"mammal-pet-doc\", \"id\": \"lion_doc\"} # Adding an id to metadata\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Elephants are the largest land animals, recognized for their remarkable intelligence and long memories.\",\n",
        "        metadata={\"source\": \"mammal-pet-doc\", \"id\": \"elephant_doc\"} # Adding an id to metadata\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cheetahs are the fastest land mammals, capable of reaching speeds up to 60–70 mph in short bursts.\",\n",
        "        metadata={\"source\": \"mammal-pet-doc\", \"id\": \"cheetah_doc\"} # Adding an id to metadata\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Dolphins are highly social marine mammals that use sophisticated vocalizations to communicate and navigate.\",\n",
        "        metadata={\"source\": \"mammal-pet-doc\", \"id\": \"dolphin_doc\"} # Adding an id to metadata\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Eagles are birds of prey with exceptional eyesight and powerful flight, often soaring at high altitudes.\",\n",
        "        metadata={\"source\": \"mammal-pet-doc\", \"id\": \"eagle_doc\"} # Adding an id to metadata\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "l85QvZabYQ0O"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y langchain langchain-core langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TWiaWKLe65d",
        "outputId": "2c08cd2f-687d-46af-8ad6-ed04f6c8cc7d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 0.1.16\n",
            "Uninstalling langchain-0.1.16:\n",
            "  Successfully uninstalled langchain-0.1.16\n",
            "Found existing installation: langchain-core 0.3.54\n",
            "Uninstalling langchain-core-0.3.54:\n",
            "  Successfully uninstalled langchain-core-0.3.54\n",
            "Found existing installation: langchain-google-genai 0.0.9\n",
            "Uninstalling langchain-google-genai-0.0.9:\n",
            "  Successfully uninstalled langchain-google-genai-0.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y langchain langchain-core langchain-google-genai\n",
        "!pip install langchain langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c4ifsxmsfSY7",
        "outputId": "48e30ac5-69cf-4637-a71c-9eaa64c556a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping langchain as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping langchain-core as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping langchain-google-genai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting langchain\n",
            "  Using cached langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
            "  Using cached langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
            "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.67.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Using cached langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "Using cached langchain_google_genai-2.1.3-py3-none-any.whl (43 kB)\n",
            "Using cached google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "Using cached langchain_core-0.3.54-py3-none-any.whl (433 kB)\n",
            "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: langchain-core, langchain-text-splitters, google-ai-generativelanguage, langchain-google-genai, langchain\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.0.2\n",
            "    Uninstalling langchain-text-splitters-0.0.2:\n",
            "      Successfully uninstalled langchain-text-splitters-0.0.2\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\n",
            "langchain-community 0.0.32 requires langchain-core<0.2.0,>=0.1.41, but you have langchain-core 0.3.54 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.17 langchain-0.3.23 langchain-core-0.3.54 langchain-google-genai-2.1.3 langchain-text-splitters-0.3.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "d560574f442a48ba9a6ebf667c109a2b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y langchain langchain-core langchain-google-genai\n",
        "!pip install langchain==0.1.16 langchain-core==0.1.42 langchain-google-genai==0.0.9\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "flIK7OFmfk-j",
        "outputId": "a0db91dd-47a5-42b4-af2c-5e667a504829"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 0.3.23\n",
            "Uninstalling langchain-0.3.23:\n",
            "  Successfully uninstalled langchain-0.3.23\n",
            "Found existing installation: langchain-core 0.3.54\n",
            "Uninstalling langchain-core-0.3.54:\n",
            "  Successfully uninstalled langchain-core-0.3.54\n",
            "Found existing installation: langchain-google-genai 2.1.3\n",
            "Uninstalling langchain-google-genai-2.1.3:\n",
            "  Successfully uninstalled langchain-google-genai-2.1.3\n",
            "Collecting langchain==0.1.16\n",
            "  Using cached langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-core==0.1.42\n",
            "  Using cached langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-google-genai==0.0.9\n",
            "  Using cached langchain_google_genai-0.0.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (3.11.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (0.0.32)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.16)\n",
            "  Using cached langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (2.11.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (8.5.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.1.42) (23.2)\n",
            "Collecting google-generativeai<0.4.0,>=0.3.1 (from langchain-google-genai==0.0.9)\n",
            "  Using cached google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.19.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (0.9.0)\n",
            "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9)\n",
            "  Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (2.38.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (2.24.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (4.13.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (5.29.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (1.26.1)\n",
            "Collecting protobuf (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9)\n",
            "  Using cached protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.16) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.1.16) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.1.16) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.16) (3.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (1.0.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (1.67.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (1.62.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.9) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.3.1)\n",
            "Using cached langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "Using cached langchain_core-0.1.42-py3-none-any.whl (287 kB)\n",
            "Using cached langchain_google_genai-0.0.9-py3-none-any.whl (17 kB)\n",
            "Using cached google_generativeai-0.3.2-py3-none-any.whl (146 kB)\n",
            "Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
            "Using cached langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Using cached protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Installing collected packages: protobuf, langchain-core, langchain-text-splitters, google-ai-generativelanguage, langchain, google-generativeai, langchain-google-genai\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.8\n",
            "    Uninstalling langchain-text-splitters-0.3.8:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.8\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.17\n",
            "    Uninstalling google-ai-generativelanguage-0.6.17:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.17\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.8.5\n",
            "    Uninstalling google-generativeai-0.8.5:\n",
            "      Successfully uninstalled google-generativeai-0.8.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-chroma 0.2.3 requires langchain-core>=0.3.52, but you have langchain-core 0.1.42 which is incompatible.\n",
            "opentelemetry-proto 1.32.1 requires protobuf<6.0,>=5.0, but you have protobuf 4.25.6 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.4.0 google-generativeai-0.3.2 langchain-0.1.16 langchain-core-0.1.42 langchain-google-genai-0.0.9 langchain-text-splitters-0.0.2 protobuf-4.25.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "a0f9fe54dde84c6cac764339c64c4494"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\",\n",
        "    google_api_key=\"AIzaSyD4gRQkOAfWHix87V7Lo7fbms8OPdEJplE\"\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "jRsaLdgDdVSY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings.embed_query(\"Who is the Founder of Pakistan ??\"))\n",
        "len(embeddings.embed_query(\"Who is the Founder of Pakistan ??\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnT_ipwSei5l",
        "outputId": "9d4daedd-9962-4278-ff98-0ea126ace591"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.053441573, -0.02480898, -0.039813872, -0.025681201, 0.06224198, 0.018381033, -0.0028861966, 0.009123479, 0.033178218, 0.055331763, -0.03687042, 0.049650863, -0.043912154, 0.026066035, -0.005391129, -0.0047342824, 0.014381513, 0.033657126, 0.04562271, -0.019687245, 0.0022560414, 0.023695681, -0.0035285375, 0.024926675, 0.0007243416, -0.0025711518, 0.017442938, -0.054783847, -0.04935295, 0.01322692, -0.02783035, 0.034821097, -0.037726995, 0.021034986, -0.012972777, -0.03935145, 0.014589148, 0.011500702, -0.035449836, 0.001587334, 0.053163446, -0.04340623, -0.046328634, 0.017139236, -0.033900667, 0.014098539, -0.056982175, 0.025901634, 0.054641984, -0.022007598, 0.03142607, 0.037704494, 0.060796484, -0.042329527, -0.020092722, -0.049202163, 0.039215844, -0.038272984, -0.014715444, 0.027858367, -0.0050453926, 0.019960778, 0.019840125, -0.009602952, -0.023345198, -0.047500268, -0.021032687, -0.00023553656, 0.038163666, 0.0133102415, -0.0046696593, 0.0003479174, 0.06947012, -0.018062243, 0.006703656, -0.13816237, 0.0036615408, 0.06151605, 0.03380558, -0.02065196, 0.016994245, -0.072868764, -0.043929175, -0.041298863, -0.023811325, 0.035017557, -0.034074936, -0.004066155, 0.018269872, 0.046449207, -0.014697771, -0.009162899, 0.041914724, -0.057227295, -0.0026242752, 0.09279393, -0.04603019, -0.040845256, 0.017757952, -0.020008879, -0.013114501, -0.038673326, -0.092409864, 0.0053159175, 0.042282544, -0.005878589, 0.043143533, 0.022276139, -0.012437579, 0.005315061, -0.048951853, 0.021352721, 0.015014769, 0.010201849, 0.031455625, -0.023617003, -0.012724237, 0.057330847, 0.026597781, 0.035184734, 0.05267585, -0.010738341, 0.06530823, -0.034888573, 0.03911337, -0.0074885474, -0.037475463, 0.03755923, 0.010163039, 0.00629871, 0.008142166, -0.04096975, -0.02639382, -0.01761134, 0.01873477, 0.064138174, 0.041936144, -0.045801263, 0.018329963, 0.017636755, -0.012796325, 0.04084445, 0.01909433, 0.011936192, 0.018867465, 0.06077202, -0.090515636, -0.0003314924, 0.06719375, -0.04076063, -0.03835894, -0.00013090804, -0.03636531, -0.032897655, 0.090174764, -0.0070414343, -0.022125047, 0.023812298, -0.011272886, 0.013452137, 0.009778731, 0.034906846, 0.030355202, 0.021070994, 0.005823702, -0.028573109, 0.0034106725, -0.015193626, 0.009384441, 0.035812255, -0.008647702, 0.029438302, -0.069532886, -0.0388679, -0.012597895, -0.05931931, 0.003533888, 0.005487229, -0.05214496, -0.013687087, 0.033673696, -0.057984244, 0.016741361, 0.052050196, 0.013642375, -0.07410038, 0.06050976, -0.0017529532, -0.033146266, 0.03222169, -0.020226067, 0.000497379, -0.023690548, -0.055297956, -0.040388662, 0.012328608, 0.054686215, 0.023108417, 0.033252027, -0.022708815, -0.008637126, 0.038850248, -0.01986792, -0.016053777, 0.020666417, -0.031717014, 0.05550129, 0.0077074454, -0.040026598, 0.02451874, -0.019048197, 0.014105418, -0.017559303, 0.025043366, 0.04595806, -0.013892307, 0.018100122, 0.050790697, 0.03191547, -0.028765492, -0.012127432, -0.00048201863, -0.01307606, -0.0026038347, 0.027448239, 0.055450916, -0.015707325, -0.0034084385, 0.020333424, -0.03227596, 0.002767271, 0.059940957, 0.025984898, -0.0014843151, 0.074475214, 0.01052293, 0.021554936, 0.018503975, 0.028751438, 0.008441681, -0.042024095, 0.023531035, 0.064241424, 0.030711036, -0.06381322, -0.05697121, -0.021230143, 0.046824627, -0.004245519, 0.06394493, 0.006382254, -0.04703122, -0.016007839, -0.001509481, -0.075574294, 0.017611703, -0.043147612, 0.020458382, -0.041983824, 0.019748982, 0.08008091, -0.0024361648, 0.015356054, -0.03030996, -0.012706138, -0.007436217, 0.030448586, -0.036276918, 0.010334045, -0.011677942, -0.016558185, -0.006556204, 0.041770816, 0.015295003, -0.021254828, 0.008995816, -0.007324925, 0.07001071, 0.00093755417, -0.059166875, 0.034609687, -0.017329201, 0.0032059446, -0.025549695, 0.01601783, 0.0077257683, -0.076331094, -0.010004109, 0.032910503, -0.0459145, -0.04421538, -0.06733912, 0.040890373, -0.039230492, -0.021654375, 0.047056485, 0.0036015671, 0.03367573, 0.030202217, -0.03298202, -0.029119646, -0.06884421, 0.06677028, -0.07541404, -0.010695578, 0.03273551, -0.04101064, -0.054748587, 0.017147915, 0.037365004, -0.024108533, 0.021477288, -0.072498076, -0.033992916, 0.038736895, 0.04050595, -0.018946916, 0.026902946, -0.00636737, 0.028986903, -0.029837146, 0.06957117, 0.009289512, 0.012210965, -0.017189443, 0.021380136, -0.00067661476, 0.016734922, -0.019949349, 0.01661124, -0.01977824, -0.013297189, -0.04285636, -0.012595647, 0.01736885, 0.05047685, -0.086176924, -0.0020440076, -0.0631675, -0.020476831, -0.003105942, 0.020564144, -0.049259376, -0.04640687, 0.01300722, -0.016073428, -0.03727805, 0.04665845, 0.06980225, 0.028045366, -0.024011705, 0.09811662, -0.013508278, 0.04371289, -0.015824746, -0.053943586, 0.035929956, -0.037026513, -0.0026254358, -0.0102668125, 0.04049535, 0.030352091, -0.030534482, -0.04856985, -0.0014313828, -0.0012530446, -0.023782553, 0.0061465474, -0.011714885, 0.06385408, 0.016709112, 0.006961484, 0.035636373, -0.055158235, 0.011839394, -0.02585526, -0.0768194, -0.019893462, 0.043718603, 0.00047670948, -0.026464164, 0.010033763, 0.04830273, 0.028510898, 0.031795785, 0.0010943075, 0.056724332, 0.015950076, -0.017545657, 0.038491193, -0.016368391, 0.032131225, 0.083186805, -0.018792266, 0.0030291423, -0.011366305, -0.0049376558, -0.030586706, 0.026153876, 0.051490553, 0.007954258, -0.0920669, -0.031303912, -0.027855495, -0.04338222, 0.052992344, 0.013048783, -0.011064721, -0.038338423, -0.0027615183, 0.010516841, 0.00807987, -0.01862163, -0.069325835, -0.03324211, -0.008987192, 0.06665409, -0.035357412, -0.02224353, 0.077753134, -0.04599299, -0.016437965, -0.021212285, 0.005865406, -0.062227286, 0.0015457758, 0.030429995, 0.043698557, -0.002127083, -0.02369246, 0.01807058, 0.024353975, -0.017169502, -0.047960028, -0.007948435, -0.04390371, -0.035267778, 0.03705485, -0.011817893, -0.016655628, 0.016730107, -0.034005973, 0.020743113, -0.007310078, -0.005483741, -0.023735033, -0.010582786, 0.00884297, 0.009775342, -0.052182652, 0.043193407, -0.03823486, -0.038504727, -0.08073651, -0.059275165, -0.025415184, -0.031713508, 0.04078418, -0.026656287, 0.02341238, -0.0062423316, -0.013565503, 0.002210324, -0.0919817, 0.03291468, 0.013726833, -0.0092267925, -0.0014231384, -0.0053578867, 0.026699258, 0.014591938, -0.008653719, -0.028445078, -0.0072455513, -0.044751685, -0.040111028, -0.06833961, 0.04300221, -0.040779784, -0.020667788, -0.016089702, 0.059537403, 0.0073912875, 0.04960583, 0.025117422, 0.014865688, -0.018765545, -0.0058722757, -0.035170894, -0.011863706, 0.022255277, 0.00036146518, -0.017690381, -0.022953486, 0.008752307, 0.039508987, -0.02005396, 0.0540786, 0.03190134, 0.007904537, -0.026775857, -0.015753413, -0.0013029486, -0.010143492, 0.047437645, -0.06350205, 0.013833091, 0.029117035, 0.04073385, -0.03200738, 0.011451774, 0.0030233024, -0.003821082, 0.021977406, 0.016682055, -0.020587113, -0.02487025, -0.008576047, 0.03846959, -0.003626203, 0.012185949, -0.033390112, -0.10827872, -0.044245373, -0.01348643, -0.058748845, 0.014879105, -0.006317108, -0.024189515, -0.01132264, -0.022478124, 0.04335125, -0.063581824, -0.022670567, 0.05870578, -0.017331835, -0.000319184, 0.0427286, -0.0028751143, 0.0032469293, 0.015216419, -0.012593509, 0.051827237, 0.0426205, -0.01936127, 0.013643427, -0.008376158, -0.07571855, -0.005092199, -0.002350447, 0.011258657, 0.01832394, 0.028861523, -0.010564658, 0.03535921, -0.0043691583, -0.0077018114, -0.02434052, 0.050261553, 0.004463481, -0.0129876835, -0.0058842786, 0.004970197, 0.0058783907, 0.06342471, -0.00963136, -0.022948015, -0.042292815, 0.058987442, -0.023336275, -0.016370786, 0.030531386, 0.015317235, -0.0041683232, 0.04716095, -0.040472288, -0.04046059, -0.017726362, -0.008659773, -0.029642332, 0.021966033, -0.019642554, 0.0041266293, 0.058788035, 0.009579883, -0.01795664, 0.085184745, 0.033316337, 0.019719664, 0.038863756, -0.060690597, 0.01354241, -0.031565204, 0.03794083, 0.008381124, 0.0043246304, 0.02529384, 0.011581442, -0.020138025, -0.017826535, 0.024888795, -0.025432905, 0.019720113, -0.007644788, 0.0415488, 0.009129942, -0.012629842, -0.004106177, 0.01420795, 0.069965184, -0.015937638, -0.050592948, 0.02176161, -0.04087703, -0.07088868, -0.048164178, 0.066659, -0.018630978, -0.042840157, -0.038216338, -0.017233267, -0.039505526, -0.0072908476, 0.0012457812, -0.017241733, 0.021484185, -0.0173063, -0.06433004, 0.09027858, 0.023065021, 0.043027345, 0.035589185, -0.026327591, 0.041733466, -0.028453082, 0.003677636, -0.011027454, 0.033607922, 0.01683293, 0.011175391, -0.09618007, -0.03282582, -0.012242107, -0.018246198, 0.008130696, 0.056304183, 0.0041839737, -0.07121049, -0.09112887, 0.0049536466, -0.0168915, 0.040546503, 0.029278556, -0.02149466, 0.027048482, 0.018122923, -0.05100044, -0.019545868, 0.02555523, -0.018331718, -0.009158306, -0.027243653, -0.046648014, -0.016297333, 0.00046979205, -0.03861258, -0.06618006, -0.115831204, -0.02577917, 0.018115602, -0.08009388, -0.02939121, 0.026527815, -0.015856769, 0.022668535, 0.009208876, -0.0015988203, 0.038792513, 0.009006832, 0.03530122, 0.04761343, 0.012418519, -0.030526258, 0.013170811, 0.017215945, 0.051592268, 0.013656852, 0.024380246, -0.017508307, -0.04653728, 0.017259263, -0.031476136, -0.019459419, 0.07962274, 0.014719693, 0.0029170776, 0.005280283, -0.009690937, 0.013917706, 0.023542993, 0.002071252, -0.061544422, -0.054250218, 0.024089288, 0.029219572, -0.008561279, 0.048413813, 0.039562605, 0.016062682, 0.08171839, 0.0007518978, -0.02986506, -0.015770877, 0.053363416, -0.00030418654, -0.06584186, 0.026471958, 0.012545226, -0.024844026, 0.07630139, 0.066367626, 0.04893209, -0.01350246, -0.004021625, -0.0436949, 0.0824572, -0.062115632, 0.022589326, 0.002397103, -0.008634918, 0.09670459, 0.0021353883, -0.04232405, 0.0431579, -0.0030893858, 0.08229804, 0.0070990827, 0.013846983, 0.020962287, -0.07918769, -0.020456366, -0.012974676, -0.0063253413, 0.0414421, 0.035352293, -0.0033371798, -0.0066501996, -0.043552894, 0.00056043256, -0.07452628, -0.027246261, 0.0044401083, -0.019387439, 0.024512235, 0.035393342, 0.02989852, 0.003479561, -0.011856244, 0.010339739, 0.017362947, -0.02947134, 0.0372783, 0.042392496, -0.013828434, 0.013799361, 0.008335895, 0.0046089725, 0.016928745]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "     Document(\n",
        "        page_content=\"Lions are majestic predators known for their strength and complex social pride structures.\",\n",
        "        metadata={\"source\": \"mammal-pet-doc\", \"id\": \"lion_doc\"} # Adding an id to metadata\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Elephants are the largest land animals, recognized for their remarkable intelligence and long memories.\",\n",
        "        metadata={\"source\": \"mammal-pet-doc\", \"id\": \"elephant_doc\"} # Adding an id to metadata\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cheetahs are the fastest land mammals, capable of reaching speeds up to 60–70 mph in short bursts.\",\n",
        "        metadata={\"source\": \"mammal-pet-doc\", \"id\": \"cheetah_doc\"} # Adding an id to metadata\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Dolphins are highly social marine mammals that use sophisticated vocalizations to communicate and navigate.\",\n",
        "        metadata={\"source\": \"mammal-pet-doc\", \"id\": \"dolphin_doc\"} # Adding an id to metadata\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Eagles are birds of prey with exceptional eyesight and powerful flight, often soaring at high altitudes.\",\n",
        "        metadata={\"source\": \"mammal-pet-doc\", \"id\": \"eagle_doc\"} # Adding an id to metadata\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Extract ids from metadata\n",
        "ids = [doc.metadata['id'] for doc in documents]\n",
        "\n",
        "vectorestore = Chroma.from_documents(\n",
        "    documents,\n",
        "    embedding=embeddings,\n",
        "    ids=ids # Pass ids explicitly\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "4BdcxeMmCLbh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dir(vectorestore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEPif2Ign4Ip",
        "outputId": "5d3b8710-bdcc-4aef-dc68-c524421d8d3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Chroma__ensure_collection',\n",
              " '_Chroma__query_collection',\n",
              " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_chroma_collection',\n",
              " '_client',\n",
              " '_client_settings',\n",
              " '_collection',\n",
              " '_collection_metadata',\n",
              " '_collection_name',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding_function',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_persist_directory',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_images',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'delete_collection',\n",
              " 'embeddings',\n",
              " 'encode_image',\n",
              " 'from_documents',\n",
              " 'from_texts',\n",
              " 'get',\n",
              " 'get_by_ids',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'override_relevance_score_fn',\n",
              " 'reset_collection',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_image',\n",
              " 'similarity_search_by_image_with_relevance_score',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_relevance_scores',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score',\n",
              " 'similarity_search_with_vectors',\n",
              " 'update_document',\n",
              " 'update_documents']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorestore.similarity_search_with_score(\"Tell me about Elephants?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYlYhTQYoD8J",
        "outputId": "6eddec4b-5689-40cd-d410-810fa0741f8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(page_content='Elephants are the largest land animals, recognized for their remarkable intelligence and long memories.', metadata={'id': 'elephant_doc', 'source': 'mammal-pet-doc'}),\n",
              "  0.4214640259742737),\n",
              " (Document(page_content='Lions are majestic predators known for their strength and complex social pride structures.', metadata={'id': 'lion_doc', 'source': 'mammal-pet-doc'}),\n",
              "  0.5565059185028076),\n",
              " (Document(page_content='Eagles are birds of prey with exceptional eyesight and powerful flight, often soaring at high altitudes.', metadata={'id': 'eagle_doc', 'source': 'mammal-pet-doc'}),\n",
              "  0.5694503784179688),\n",
              " (Document(page_content='Cheetahs are the fastest land mammals, capable of reaching speeds up to 60–70 mph in short bursts.', metadata={'id': 'cheetah_doc', 'source': 'mammal-pet-doc'}),\n",
              "  0.5847951173782349)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def callFunction():\n",
        "    await vectorestore.similarity_search(\"Tell me about Elephants?\")\n",
        "\n",
        "callFunction()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIIQiia5ot6g",
        "outputId": "1b34f67a-1d17-4cac-ad0d-0a3e734332b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<coroutine object callFunction at 0x7df52cd06380>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = embeddings.embed_query(\"Tell me about Elephants?\")\n",
        "print(embedding)\n",
        "vectorestore.similarity_search_by_vector(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMG4Dqudp8r2",
        "outputId": "9dfce9f2-8acc-4738-f7b8-46a11f548159"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.055688363, -0.01197878, -0.064529635, -0.032824736, 0.031692058, 0.014053445, 0.010907943, 0.000290777, -0.023533853, 0.08779333, 0.0061508254, -0.009162713, 0.024952231, -0.0069084475, -0.001381451, -0.021140344, 0.0112999845, 0.03207541, 0.08141247, -0.023158824, 0.013611537, 0.018501926, 0.022187911, 0.016247721, 0.025593398, -0.028130682, -0.0008706348, -0.061663847, -0.0045179175, 0.017984107, -0.037871033, 0.050107256, -0.03761555, 0.012789056, 0.029336592, -0.08113298, -0.024661336, 0.010394937, 3.904661e-05, 0.004027777, 0.01126696, -0.014626121, -0.080241896, 0.030045966, -0.0067566964, -0.020954156, -0.050434664, 0.081348784, 0.0076729856, -0.018509166, -0.0054753306, -0.00017145764, 0.058649287, -0.0234116, 0.0016035434, -0.08906826, 0.046640724, -0.05213009, -0.023229297, 0.050657585, -0.0008577941, -0.019096803, -0.0050336155, 0.031102546, -0.017882079, -0.05790744, -0.053715102, 0.022812283, 0.054505046, -0.006706614, -0.009192973, -0.060780767, 0.028138898, 0.023729756, 0.015970003, -0.07166759, -0.018472983, 0.063111514, -0.011872067, -0.030127933, 0.025732914, -0.025874676, -0.06697921, -0.0083306655, -0.069099285, 0.03075392, -0.028633118, -0.03027476, 0.0015277194, 0.087746866, -0.014670755, 0.013481552, 0.054864056, -0.025989493, -0.0037169517, 0.07218641, -0.062646225, -0.0009540863, 0.046968427, -0.0046479446, -0.009230467, -0.008051351, -0.06959618, 0.018038472, 0.013288721, -0.0152285285, 0.0032216473, 0.061106984, -0.0043185623, 0.015098865, -0.040263165, 0.010789404, 0.0002931814, 0.01776823, 0.023352768, -0.045049433, 0.014534809, 0.012905035, 0.0041599786, -0.0022344317, 0.022988478, 0.0026877134, 0.121313035, -0.02328581, 0.024897426, 0.026995176, -0.019601446, 0.012755864, 0.0043883054, 0.037114076, 0.0061290683, -0.05229534, -0.006094183, -0.0018041191, 0.00566461, 0.06950233, 0.025484981, -0.004400696, 0.0103048915, -0.018461425, -0.0076304297, 0.023057446, 0.020387346, 0.035858415, -0.031516705, 0.078957975, -0.0743426, -0.024680613, 0.060338877, -0.041551303, -0.047000136, 0.0172021, -0.055615194, -0.039989874, 0.037131067, 0.0008354424, -0.011706533, 0.057828628, -0.0049611186, -0.013752135, 0.026698302, 0.041730046, 0.028647546, -0.013855155, -0.017344175, -0.0557033, -0.011558037, -0.002748256, -0.046898194, -0.011357116, -0.049055744, 0.0077440063, -0.0198547, -0.029791506, -0.010173544, -0.052021645, 0.06172729, -0.020661257, -0.034142677, -0.025561277, -0.0008634385, -0.078863405, 0.017102728, 0.040981505, 0.026902696, -0.044647865, 0.05300613, -0.0058176736, -0.010770987, 0.007956237, -0.01305165, -0.03090836, -0.040076807, -0.004713179, -0.03503524, -0.000554951, 0.00512612, -0.025766682, 0.01884, -0.05326242, -0.010376642, 0.041442454, 0.04580649, -0.028137453, 0.034900427, -0.02596691, 0.08571513, -0.044538483, -0.048650343, 0.030233135, -0.019646164, 0.0282757, -0.012634051, -0.0037689172, 0.024286665, -0.009939935, 0.047757883, 0.050537728, 0.006101641, -0.024975797, -0.055787325, -0.028791621, -0.049425144, 0.019691702, 0.004843077, 0.006956535, -0.01025864, -0.0012133276, -0.0025550385, -0.0646235, -0.01168303, 0.0296514, 0.03547126, -0.015045158, 0.08461208, 0.0011765322, 0.009416744, -0.020108359, 0.0018551431, 0.023002636, -0.05541326, -0.02054071, 0.03955036, 0.062763125, -0.042064175, -0.040784955, -0.038774848, 0.0037145084, 0.03555396, 0.06568795, 0.005587779, -0.0684577, -0.008187314, 0.024886834, -0.05802114, 0.01661189, -0.050818425, 0.05910808, -0.032153014, 0.0080362735, 0.02254836, 0.005458834, 0.026628207, -0.016667858, -0.036599576, -0.04766851, -0.0038236966, -0.08003463, 0.027096279, 0.019037934, 0.021143822, -0.0357039, 0.03332353, 0.030118054, 0.03255749, 0.037833504, -0.026438216, 0.065358244, 0.009458184, -0.076346174, 0.008037294, 0.06706931, 0.016340597, -0.024641473, 0.0044511193, -0.019215351, -0.020609038, -0.01454906, -0.003952711, -0.012596999, 0.00400199, -0.04210799, 0.024181414, -0.048495863, -0.029107006, 0.007061382, 0.0030177017, 0.016313566, 0.022405397, -0.050353214, -0.031651795, -0.041426424, 0.006858256, -0.08162823, -0.0111064995, 0.009311852, -0.06725805, -0.06649366, 0.025613898, 0.04358941, 0.0018499922, 0.020954452, -0.054527733, -0.032777775, -0.006118681, 0.06691166, -0.03234037, -2.6562235e-05, 0.011816072, 0.019284265, -0.0061537125, 0.09856555, -0.017202362, -0.0070877187, -0.016186148, 0.046782013, 0.0019034287, 0.06134547, 0.0122390725, -0.004885691, -0.031841084, 0.019803723, -0.0423939, 0.008018608, -0.0020728912, 0.051241755, -0.09531614, 0.01058333, -0.07342613, 0.009487102, 0.034509543, 0.0022226807, -0.0013653662, -0.048677046, 0.00353453, -0.014801707, -0.045589454, 0.014926298, 0.08133229, 0.02812764, 0.016102053, 0.05629643, 0.027132334, 0.036494274, -0.0075020366, -0.00482908, 0.038599353, -0.026723262, 0.01453787, -0.057195935, 0.009321124, 0.0204245, -0.021111133, -0.02532805, -0.02630952, -0.043549642, -0.005462432, 0.048433628, 0.007973864, 0.043185733, 0.033511158, 0.011301319, 0.012554766, -0.036244296, 0.0028978856, -0.017626585, -0.05857142, -0.0158466, 0.029024428, 0.01801179, -0.03244115, -0.017620446, 0.028285244, -0.014663276, 0.02703328, -0.011645567, -0.0042236345, -0.016219227, -0.016935145, 0.06975941, -0.030957662, 0.034227338, 0.076832, -0.02578758, 0.0048546786, 0.024546288, 0.017284634, -0.021976814, -0.016207088, 0.03249889, -0.020833302, -0.05907905, -0.034158137, -0.0035656404, -0.040835008, -0.012255708, 0.007886845, -0.014687451, -0.034638293, 0.029529983, -0.0015512652, 0.020314716, -0.0034491883, -0.06565549, -0.045341626, -0.025284668, 0.076316826, 0.005124054, 0.009696316, 0.05866083, -0.010867221, -0.014924039, 0.021988278, -0.008181679, -0.08575072, -0.083290525, -0.0053421, 0.018240876, 0.020348141, 0.04848556, 0.026946226, -0.00046566388, -0.006970012, -0.041568153, -0.01763089, -0.06308474, 0.017832723, 0.0397318, 0.022958344, -0.0033168702, -0.0007617962, -0.044782482, 0.026523255, -0.005744097, -0.07596491, 0.013794701, -0.021788605, 0.019269506, 0.018493973, -0.08153552, 0.03296575, -0.0640196, -0.013767924, -0.08283699, -0.039289158, -0.016453506, 0.04267661, 0.076813474, -0.05746655, 0.014320861, -0.007462521, -0.02828811, -0.016445864, -0.12542643, 0.061365254, 0.016275661, 0.015668748, 0.00789268, 0.009582988, 0.036594905, 0.011098796, -0.012079202, -0.0019962203, -0.0012738423, -0.045939006, -0.021926418, -0.047926333, 0.029892862, -0.047406062, -0.057110094, -0.012051562, 0.045905117, -0.009035209, 0.046980977, -0.031133998, 0.028988404, 0.0011291361, -0.0029303404, -0.013566329, 0.036461104, -0.00016503087, 0.0017273526, 0.031184372, -0.04071921, -0.009691288, -0.033327084, -0.014329364, 0.028004715, 0.023864236, 0.004796129, -0.046855707, -0.02628341, 0.008174478, -0.05021898, 0.08899483, -0.053506773, -0.023579713, 0.0051010703, -0.0035099154, -0.029420529, 0.019256279, 0.04866686, 0.002560295, 0.013753134, 0.035182722, -0.016388958, 0.017546972, 0.008100008, -0.007734982, -0.008936496, 0.0719577, 0.0239324, -0.070411816, -0.002016402, 0.005852071, 0.00038354978, 0.029675882, 0.0046941694, -0.039500125, 0.0217661, -0.024376774, 0.061696835, -0.04412808, -0.022191634, 0.011275681, -0.027042123, 0.006928473, 0.034647588, 0.030080637, -0.0040377867, 0.0010665392, -0.045361202, 0.008691057, 0.0480619, -0.029486876, 0.02953206, 0.014151377, -0.07157169, 0.0060512396, 0.023635346, -0.012601422, 0.023428563, 0.023827363, -0.02631362, -0.024399422, -0.025140509, -0.025490621, 0.032727063, 0.018477501, -0.023772834, 0.010014228, -0.014414064, 0.019651122, 0.02988815, 0.043816026, 0.012270337, -0.017248971, -0.060789187, 0.057331555, 0.026868029, -0.00864062, 0.020847188, 0.012553496, 0.042721134, -0.0007477695, -0.02034829, -0.036749, -0.020789584, -0.008962375, -0.009551531, 0.036326304, -0.026176037, 0.0055298503, 0.030829718, 0.022045719, -0.015646601, 0.054936294, 0.061566442, 0.022012997, 0.037007242, -0.041381855, 0.023204686, -0.060909983, -0.0023613058, 0.00848006, 0.0036611697, -0.021279212, -0.008362244, -0.014968489, -0.012011195, 0.054838914, -0.0015656875, 0.02199213, -0.013909772, 0.015702715, 0.037138436, -0.022225125, -0.017374162, 0.028320594, 0.04235169, -0.018777084, -7.750009e-05, 0.0066978694, -0.02468177, -0.021528084, -0.015460964, 0.09627229, -0.045682427, -0.00015359318, -0.005136638, -0.03993759, -0.010775868, 0.013709484, 0.0028503833, 0.042293116, 0.051083967, 0.0135056265, -0.021880973, 0.06657673, 0.042773712, 0.034856014, 0.09438392, 0.021975512, 0.024764515, -0.07746404, -0.001929949, -0.031072333, -0.004897322, 0.03246449, -0.012795893, -0.0658434, 0.0050881207, -0.027587712, -0.031296767, -0.009484039, 0.09560223, 0.022670008, -0.056820817, -0.044981264, -0.008493433, -0.029518975, -0.01666299, 0.045288153, -0.015548497, -0.002164581, 0.014172983, -0.034787927, -0.070328906, -0.015852317, -0.011570763, -0.0027723983, -0.025379093, 0.020104237, 0.010967549, -0.0051373476, -0.023766065, -0.022495644, -0.065929234, -0.006233199, 0.081489824, -0.034656852, 0.061962593, 0.034680706, -0.009228267, 0.02936786, -0.0030827762, 0.004416957, 0.032396145, 0.061008412, 0.013867593, -0.00405225, -0.008217222, -0.04320872, 0.009696776, 0.012975847, 0.041988447, -0.00093899184, 0.035045076, -0.05084357, -0.03460071, -0.023486134, -0.024660155, -0.057423063, 0.047507513, 0.03205616, 0.024326874, -0.016448066, -0.011131108, -0.021685496, -0.020852702, -0.05127494, -0.027954288, 0.0022706497, 0.0023672818, 0.0039686374, 0.028730316, 0.004069539, 0.014607922, 0.058148224, 0.05207751, 0.06115577, -0.033749517, -0.014505973, 0.008418012, 0.010596621, -0.021104695, -0.0054285754, 0.031944964, -0.037736878, 0.045290314, 0.051225122, 0.027863745, 0.037785787, -0.025014453, -0.091678366, 0.047413066, -0.06280318, -0.033456467, 0.012758534, 0.0056965165, 0.09301735, -0.01200995, -0.023309039, 0.02457311, -0.0202887, 0.11462387, 0.027400494, 0.040663354, -0.00123181, -0.06827801, -0.024979522, 0.005520064, 0.03667807, 0.06812025, 0.011517826, 0.0072083226, -0.01684307, -0.06253083, -0.019400217, -0.03945267, -0.018077677, 0.025752518, -0.029643295, 0.011024797, 0.02469118, 0.0034937607, -0.015183155, -0.019011816, -0.0030263274, -0.017473217, -0.037970867, -0.041962143, -0.029987717, 0.0026955649, 0.0528503, 0.033853617, 0.027113073, -0.006504429]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Elephants are the largest land animals, recognized for their remarkable intelligence and long memories.', metadata={'id': 'elephant_doc', 'source': 'mammal-pet-doc'}),\n",
              " Document(page_content='Lions are majestic predators known for their strength and complex social pride structures.', metadata={'id': 'lion_doc', 'source': 'mammal-pet-doc'}),\n",
              " Document(page_content='Eagles are birds of prey with exceptional eyesight and powerful flight, often soaring at high altitudes.', metadata={'id': 'eagle_doc', 'source': 'mammal-pet-doc'}),\n",
              " Document(page_content='Cheetahs are the fastest land mammals, capable of reaching speeds up to 60–70 mph in short bursts.', metadata={'id': 'cheetah_doc', 'source': 'mammal-pet-doc'})]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QNvMIBHqNp2",
        "outputId": "22cfac28-351f-49df-a0ed-05cc72eb374f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reteriver **"
      ],
      "metadata": {
        "id": "pSI1Ser7rFsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever = RunnableLambda(vectorestore.similarity_search).bind(k=1)\n",
        "retriever.batch([\"Tell me about Lions?\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRWfJc4qrLVq",
        "outputId": "d15419aa-6ff8-434e-fce4-a3200be3a5fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Document(page_content='Lions are majestic predators known for their strength and complex social pride structures.', metadata={'id': 'lion_doc', 'source': 'mammal-pet-doc'})]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AF9p2Cz0rlNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Augment Mean**"
      ],
      "metadata": {
        "id": "2dCjxzkUqk_j"
      }
    },
    {
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "# Set the API key as an environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD4gRQkOAfWHix87V7Lo7fbms8OPdEJplE\"\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        ")\n",
        "llm"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z_yvCjYCcxA",
        "outputId": "cea5e9b2-9f9d-4f75-fb47-1132718ae7bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGoogleGenerativeAI(model='gemini-1.5-flash', client= genai.GenerativeModel(\n",
              "   model_name='models/gemini-1.5-flash',\n",
              "   generation_config={}.\n",
              "   safety_settings={}\n",
              "))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Kv2nFl0xt3Pt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([(\"human\",message)])"
      ],
      "metadata": {
        "id": "1oWgzBTqug18"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rag**"
      ],
      "metadata": {
        "id": "H5x0Yl5vvLih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = {\"context\" : retriever, \"question\" : RunnablePassthrough()} | prompt | llm"
      ],
      "metadata": {
        "id": "tKe6EPuMu6ER"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"Tell ma about Cheetahs?\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzdxqgaevfZg",
        "outputId": "6d9cf931-6508-4616-a96b-48082c1d2527"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cheetahs are the fastest land mammals, reaching speeds of 60–70 mph in short bursts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq facenet-pytorch"
      ],
      "metadata": {
        "id": "YoiWJ-2T3gdA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQZ5strC32oO",
        "outputId": "906c938d-6faf-4ba4-d009-c785697ad35b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 11.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jASiMPfo5H3i",
        "outputId": "19f1eb43-97f7-449a-f9fa-05754cb1c9b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InceptionResnetV1(\n",
              "  (conv2d_1a): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2a): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2b): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2d_3b): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4a): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4b): BasicConv2d(\n",
              "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (repeat_1): Sequential(\n",
              "    (0): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_6a): Mixed_6a(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_2): Sequential(\n",
              "    (0): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_7a): Mixed_7a(\n",
              "    (branch0): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_3): Sequential(\n",
              "    (0): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (block8): Block8(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
              "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (logits): Linear(in_features=512, out_features=8631, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "  image = Image.open(image_path).convert(\"RGB\")\n",
        "  preprocess = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "  return preprocess(image).unsqueeze(0)"
      ],
      "metadata": {
        "id": "fB7cgUXx6Bfp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_image_embedding(image_path):\n",
        "  try:\n",
        "    input_tensor = preprocess_image(image_path)\n",
        "    with torch.no_grad():\n",
        "      embeddings = model(input_tensor)\n",
        "    return embeddings.squeeze().numpy()\n",
        "  except Exception as e:\n",
        "    print(f\"Error creating embedding: {e}\")  # Print the exception details\n",
        "    return None"
      ],
      "metadata": {
        "id": "_s6GnPfn65Hv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjmBKrHz7o2W",
        "outputId": "919bd4c9-41d1-47ce-9971-ef29a07f2227"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘images’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "def save_image_from_url(image_url, image_name):\n",
        "  \"\"\"\n",
        "  Dowload an image from a URL save it to 'images' folder\n",
        "\n",
        "  Args:\n",
        "    image_url: The URL of the image to download\n",
        "    image_name: The Name of the file to save the image as\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if not os.path.exists(\"images\"):\n",
        "      os.makedirs(\"images\")\n",
        "\n",
        "    image_path = os.path.join(\"images\", image_name)\n",
        "\n",
        "    response = requests.get(image_url, stream=True)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    with open(image_path, \"wb\") as file:\n",
        "      for chunk in response.iter_content(chunk_size=8192):\n",
        "        file.write(chunk)\n",
        "\n",
        "    print(f\"Image saved at: {image_path}\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading image: {e}\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error Occur in saving image: {e}\")"
      ],
      "metadata": {
        "id": "QUtPB4QT75Y9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_image_from_url(\"https://images.unsplash.com/photo-1579353977828-2a4eab540b9a?fm=jpg&q=60&w=3000&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8Mnx8c2FtcGxlfGVufDB8fDB8fHww\" , \"jetha1.jpg\")\n",
        "save_image_from_url(\"https://images.unsplash.com/photo-1579353977828-2a4eab540b9a?fm=jpg&q=60&w=3000&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8Mnx8c2FtcGxlfGVufDB8fDB8fHww\" , \"jetha2.jpg\")\n",
        "save_image_from_url(\"https://images.unsplash.com/photo-1579353977828-2a4eab540b9a?fm=jpg&q=60&w=3000&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8Mnx8c2FtcGxlfGVufDB8fDB8fHww\" , \"jetha3.jpg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB4DKiQQ8Ouf",
        "outputId": "0b782cc8-6655-4f67-ca81-0fa2542b6868"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved at: images/jetha1.jpg\n",
            "Image saved at: images/jetha2.jpg\n",
            "Image saved at: images/jetha3.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"./images/jetha1.jpg\"\n",
        "print(image_path)\n",
        "q2 = create_image_embedding(image_path)\n",
        "print(q2.shape)\n",
        "print(q2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giMkVy37CgKQ",
        "outputId": "850b4d5c-ed4a-4d78-ecd7-9bf25552a52e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./images/jetha1.jpg\n",
            "(512,)\n",
            "[-1.71652418e-02 -2.14226749e-02 -3.69014032e-02  9.17513743e-02\n",
            " -1.07421661e-02  4.66365442e-02 -1.84217598e-02  1.65924802e-02\n",
            " -1.22968722e-02  8.23152065e-03  3.27579677e-03  3.28216441e-02\n",
            " -1.43943066e-02 -6.44056546e-03  4.68005566e-03 -1.52205955e-02\n",
            "  2.90533975e-02  2.26288419e-02 -2.85093486e-02 -7.26297647e-02\n",
            " -5.86174317e-02  2.14552786e-02  4.49853763e-02  7.51551390e-02\n",
            " -9.40291490e-03  6.26153126e-02  1.09860962e-02  1.42451199e-02\n",
            " -8.72330647e-03  4.64042500e-02 -4.78688218e-02 -4.83297789e-03\n",
            " -1.03868255e-02 -4.19501662e-02 -5.24999574e-02  6.82094321e-02\n",
            " -5.42349741e-02 -5.39837265e-03 -4.61527966e-02  4.22852933e-02\n",
            "  3.40135992e-02 -1.45326378e-02  2.34187171e-02 -1.49338553e-02\n",
            "  4.72984537e-02  3.89861651e-02 -1.95441060e-02  3.26468647e-02\n",
            " -4.88797799e-02  9.26305726e-03  7.05186874e-02  4.72084582e-02\n",
            "  2.21766699e-02  4.64807898e-02 -9.69932154e-02  1.51591217e-02\n",
            "  6.08548755e-03  3.86114907e-03  2.43247580e-02 -1.96755771e-02\n",
            "  3.33704054e-02  3.38380598e-02 -4.74430667e-03 -5.90540320e-02\n",
            " -1.71243458e-03  9.27992612e-02 -1.04533266e-02 -2.88959555e-02\n",
            "  2.08191015e-02  9.67317075e-02  6.67207241e-02  7.62426257e-02\n",
            "  1.74782169e-03  2.07658531e-03 -1.81955863e-02  4.55280207e-02\n",
            " -7.14628473e-02 -1.77442115e-02 -5.55112138e-02  8.35447088e-02\n",
            "  7.71423280e-02  3.16116922e-02  4.28386498e-03  2.95720082e-02\n",
            "  5.77182584e-02  9.44182929e-03  3.09709273e-02  2.07091179e-02\n",
            "  1.19701214e-02 -1.27841244e-02  1.94323864e-02  1.39188711e-02\n",
            "  4.63138781e-02 -1.92109635e-03  9.46068242e-02 -1.86541479e-03\n",
            " -2.58588493e-02 -2.65322253e-02 -2.77669095e-02  5.34552410e-02\n",
            "  2.69377623e-02 -5.80563806e-02 -1.16699450e-02  3.41869816e-02\n",
            " -2.02150512e-02  8.78650472e-02  2.41626911e-02  4.24906658e-03\n",
            " -3.00677698e-02 -1.78718362e-02 -1.73427397e-03 -8.76720157e-03\n",
            " -6.80878833e-02 -4.45001014e-02 -2.42025312e-02 -1.01080529e-01\n",
            " -3.11668776e-02 -4.02847901e-02 -7.68085495e-02  1.39082009e-02\n",
            " -1.49950841e-02  1.52841676e-02 -7.74892569e-02 -5.60683161e-02\n",
            " -2.66029350e-02 -1.06912248e-01 -5.52712679e-02  7.40672201e-02\n",
            "  3.76071781e-03 -3.38090882e-02 -2.42280457e-02 -8.25715885e-02\n",
            "  3.43487747e-02  8.68472634e-05 -1.14248291e-01  2.92813778e-02\n",
            "  1.33774271e-02 -2.42300052e-02  6.08405937e-03  1.18474692e-01\n",
            "  3.08750123e-02  4.22719382e-02  4.85849045e-02  5.72910495e-02\n",
            "  1.99655201e-02 -1.52962022e-02  4.35380684e-03 -6.39681378e-03\n",
            " -4.47917953e-02 -1.46187693e-02 -1.93671305e-02 -2.50646230e-02\n",
            " -5.84607162e-02  6.63697794e-02  4.06754725e-02 -5.47326431e-02\n",
            "  2.38423585e-03  4.42523807e-02  1.64759140e-02 -3.04594766e-02\n",
            "  1.04979724e-01  2.94528194e-02 -3.16681936e-02  8.34025741e-02\n",
            "  6.17961399e-02 -1.34688169e-02 -2.84590963e-02 -7.20835850e-02\n",
            "  5.67105552e-03 -5.88863995e-03 -5.13223819e-02  3.43222246e-02\n",
            " -4.61341999e-02 -1.38992351e-03  2.70721521e-02  6.94664642e-02\n",
            "  8.55608061e-02 -1.73890982e-02 -7.46101514e-02 -3.01024094e-02\n",
            " -9.10803825e-02 -5.72861657e-02 -6.47161081e-02  2.41919365e-02\n",
            " -8.01742263e-03 -1.69787593e-02  1.44500509e-02  1.37035437e-02\n",
            "  4.51037614e-03  1.03416899e-02  2.53961626e-02 -2.26701982e-02\n",
            "  9.27313268e-02 -6.10341392e-02  2.11146730e-03 -3.46916951e-02\n",
            "  4.16182131e-02 -3.14076804e-02 -4.31525856e-02  5.11416607e-02\n",
            "  2.84966305e-02  7.33192116e-02 -2.08645742e-02 -2.05942132e-02\n",
            "  2.54515428e-02  2.56982204e-02  2.99694315e-02 -4.91666012e-02\n",
            " -1.32797193e-02  3.74200791e-02  2.06470061e-02 -6.58948033e-04\n",
            " -3.02020647e-02  1.52749522e-02  3.61053972e-04 -7.19102565e-03\n",
            " -7.70405605e-02  5.03438190e-02 -4.58404869e-02  2.71898881e-02\n",
            " -5.60119888e-03 -9.98641029e-02 -4.05901223e-02 -1.73468459e-02\n",
            " -2.94468198e-02 -5.34161702e-02 -2.61059850e-02 -1.94981857e-03\n",
            " -5.26598021e-02 -8.99355114e-03  3.97294685e-02  3.65278535e-02\n",
            " -1.80845335e-02 -8.65160525e-02 -3.26273888e-02  8.36857501e-03\n",
            "  1.74296629e-02  4.96954545e-02 -9.21559930e-02  2.97430181e-03\n",
            "  1.98876485e-02  2.05321889e-03 -1.37190716e-02  4.48528677e-02\n",
            "  6.02802075e-02  7.92442784e-02  3.34962830e-02  9.06707421e-02\n",
            "  7.29662925e-03  4.28409614e-02 -2.07978617e-02  4.77605797e-02\n",
            " -7.08391308e-05  2.91046631e-02  4.36879694e-02  4.42388207e-02\n",
            " -1.42221863e-03 -2.37643858e-03  4.93517099e-03  1.07808307e-01\n",
            "  6.10910766e-02 -2.08560172e-02  2.02932712e-02 -6.19768873e-02\n",
            " -3.15881334e-02  3.23432731e-04 -2.71387473e-02  8.27359501e-03\n",
            " -6.40115663e-02 -2.49079033e-03 -3.11468374e-02 -6.54108673e-02\n",
            "  5.14276233e-03  1.90644059e-02  8.04698393e-02 -1.25988470e-02\n",
            " -1.08505907e-02 -2.90352348e-02 -2.47324035e-02 -2.50309557e-02\n",
            "  4.28696163e-02 -3.21229808e-02 -7.54252672e-02 -9.14921388e-02\n",
            " -7.61295706e-02 -1.69333238e-02 -2.68962532e-02  8.29378963e-02\n",
            " -5.91394305e-02 -7.36671537e-02  2.40776278e-02 -5.03061861e-02\n",
            "  5.40711358e-02 -5.12632318e-02 -2.35552192e-02 -8.82556960e-02\n",
            "  1.60590594e-03  4.11888286e-02  5.66200912e-03  1.54308928e-02\n",
            "  7.24300295e-02 -5.00140116e-02  8.91470388e-02 -7.93656260e-02\n",
            "  6.02934361e-02 -3.13523225e-02 -5.38020441e-03 -7.14906119e-03\n",
            "  3.93287577e-02 -1.55037618e-03  3.77800055e-02  2.28404347e-02\n",
            "  1.82885677e-02  3.60336527e-02  4.74462025e-02  2.42534578e-02\n",
            " -4.50962372e-02  4.94615212e-02 -2.87480187e-02  1.22758308e-02\n",
            "  6.25258014e-02 -2.04453468e-02  1.95486546e-02  1.63090918e-02\n",
            " -2.87040174e-02  1.00978119e-02 -1.26024475e-02  1.56414974e-02\n",
            "  6.41459227e-02  3.81928086e-02  6.59289584e-02 -1.38135236e-02\n",
            " -1.73554383e-02  9.83952507e-02  5.11847399e-02  3.30670103e-02\n",
            " -4.18189168e-02  1.32481456e-02  2.12714281e-02 -1.81636214e-02\n",
            "  5.47896000e-03  1.47600537e-02  7.24944472e-02 -3.98397632e-02\n",
            "  3.02406177e-02 -7.49227479e-02 -1.16230631e-02  7.18680099e-02\n",
            "  3.46821956e-02 -5.02614165e-03 -1.86779704e-02  1.04528368e-02\n",
            " -7.68906772e-02 -3.62794138e-02 -4.94624935e-02  7.62295648e-02\n",
            "  3.16861644e-02 -1.90391000e-02  2.61455961e-02  2.02991497e-02\n",
            " -2.80942079e-02  7.82251135e-02 -2.17106193e-02  8.77867732e-03\n",
            " -3.36996280e-02  4.09158226e-03  7.40962625e-02  4.44274470e-02\n",
            "  5.36636589e-03 -8.09258223e-02  1.95319746e-02 -3.17919180e-02\n",
            "  6.79097846e-02  4.77874242e-02  3.46744396e-02  7.08520859e-02\n",
            " -1.85274705e-02  2.36676205e-02 -6.54487461e-02 -6.40109330e-02\n",
            "  3.89027707e-02  3.58386640e-03 -6.28291145e-02  3.47860977e-02\n",
            " -1.17666097e-02 -2.18544882e-02 -2.43917350e-02 -4.52139154e-02\n",
            " -1.77082408e-03 -2.95307599e-02  5.24160191e-02 -2.14996021e-02\n",
            " -3.61010283e-02 -6.67097792e-02 -6.76639602e-02 -5.37361950e-02\n",
            "  2.08320580e-02 -9.26018041e-03 -1.01517849e-02  4.28468473e-02\n",
            " -5.29465452e-02  7.28353113e-02 -2.71648262e-02  1.45297488e-02\n",
            " -4.98832092e-02  5.29044261e-03  6.44309744e-02 -6.53474256e-02\n",
            "  9.10133310e-03 -1.42408805e-02 -4.75462712e-03 -2.64120623e-02\n",
            "  8.31066817e-02 -1.45917328e-03  4.65334691e-02 -4.06028610e-03\n",
            " -1.75112975e-03  2.56304760e-02 -3.91134992e-02 -2.30626948e-02\n",
            "  4.78563085e-02  8.86250054e-04 -2.94300131e-02 -3.51708988e-03\n",
            " -1.85441691e-02 -6.22772519e-03  4.03431952e-02  1.08352499e-02\n",
            "  7.81803429e-02 -7.45634660e-02 -1.72693674e-02  1.80402007e-02\n",
            " -1.50014432e-02 -6.51457906e-02 -5.59818260e-02 -2.48144269e-02\n",
            " -1.32891256e-02  2.23462135e-02  9.06735938e-03 -3.13866585e-02\n",
            " -8.59012529e-02  2.10043751e-02 -6.51899129e-02  9.52003300e-02\n",
            " -8.68617520e-02  2.27035657e-02 -4.02060896e-02  3.02489623e-02\n",
            " -5.67882732e-02 -3.17782015e-02 -3.95602472e-02  1.86127443e-02\n",
            "  1.83867216e-02 -7.55732358e-02 -1.77232847e-02  1.70455612e-02\n",
            "  2.85846721e-02  8.69785547e-02  2.58358754e-02  2.21930351e-02\n",
            " -5.11378683e-02  9.06218030e-03  5.09728212e-03  3.96288112e-02\n",
            "  8.82079527e-02 -6.14260416e-03 -5.75170517e-02 -2.42777597e-02\n",
            "  1.05726020e-02 -6.88147172e-02  2.95409150e-02 -2.93106819e-03\n",
            "  2.88098603e-02 -5.27210273e-02 -9.19215381e-02  7.11615337e-03\n",
            "  7.92758912e-02  1.31641189e-02  5.54478727e-02  3.81460274e-03\n",
            "  4.02279012e-02 -1.16900625e-02 -1.73248127e-02 -1.08749988e-02\n",
            " -4.93909977e-03  4.39072549e-02 -1.11912362e-01  2.90232580e-02\n",
            " -1.07661877e-02 -3.05820070e-02  3.21460031e-02 -3.47666047e-03\n",
            "  3.12222745e-02 -5.72177321e-02  5.53461947e-02 -6.34792671e-02\n",
            " -1.23266317e-02 -5.11319414e-02  3.57259018e-03 -1.66666768e-02\n",
            " -3.09683867e-02  2.47310940e-02  1.23976469e-02  1.68150421e-02\n",
            "  2.36362382e-03  7.56094009e-02  4.82997335e-02  4.14109565e-02\n",
            "  1.30790398e-02 -6.68270001e-03  2.04597805e-02 -6.34549111e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = create_image_embedding('./images/jetha1.jpg')\n",
        "r2 = create_image_embedding('./images/jetha2.jpg')\n",
        "r3 = create_image_embedding('./images/jetha3.jpg')"
      ],
      "metadata": {
        "id": "uzWV_ZJWHP4q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U milvus-lite\n",
        "\n",
        "!pip install -U pymilvus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZT5toFeHgp_",
        "outputId": "9d4d158f-b9d4-4b9b-8fbd-381755b7b70d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: milvus-lite in /usr/local/lib/python3.11/dist-packages (2.4.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from milvus-lite) (4.67.1)\n",
            "Requirement already satisfied: pymilvus in /usr/local/lib/python3.11/dist-packages (2.5.6)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (75.2.0)\n",
            "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (1.67.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (4.25.6)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (1.1.0)\n",
            "Requirement already satisfied: ujson>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (5.10.0)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (2.2.2)\n",
            "Requirement already satisfied: milvus-lite>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (2.4.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from milvus-lite>=2.4.0->pymilvus) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "client = MilvusClient('./milvus_demo.db')\n",
        "client.list_collections()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzZgyLfxIDOk",
        "outputId": "214a151b-a8b0-4621-b55f-0b0a7ce3d665"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['images']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "import numpy as np\n",
        "\n",
        "client = MilvusClient('./milvus_demo.db')\n",
        "client.create_collection(\n",
        "    collection_name=\"images\",\n",
        "    dimension=512,\n",
        ")\n",
        "\n",
        "\n",
        "r1 = create_image_embedding('./images/jetha1.jpg')\n",
        "r2 = create_image_embedding('./images/jetha2.jpg')\n",
        "r3 = create_image_embedding('./images/jetha3.jpg')\n",
        "\n",
        "data = [\n",
        "  {\"id\"  : 1, \"person_name\" : f\"jetha 1\" , \"vector\" : r1}, # Change id to \"id\"\n",
        "  {\"id\"  : 2, \"person_name\" : f\"jetha 2\" , \"vector\" : r2}, # Change id to \"id\"\n",
        "  {\"id\"  : 3, \"person_name\" : f\"jetha 3\" , \"vector\" : r3}, # Change id to \"id\"\n",
        "]\n",
        "\n",
        "res  = client.insert(\n",
        "    collection_name=\"images\",\n",
        "    data=data\n",
        ")"
      ],
      "metadata": {
        "id": "HovWBDyXIcje"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data=[r1],\n",
        "    limit=1,\n",
        "    output_fields=[\"id\" , \"person_name\"]\n",
        ")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcrQe_bMv0e",
        "outputId": "a5ac67b4-146c-4bc8-a583-b138f4740404"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 1, 'distance': 1.000000238418579, 'entity': {'person_name': 'jetha 1', 'id': 1}}]\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v4 = create_image_embedding(\"./images/jetha1.jpg\")\n",
        "v4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri4uP0g-NZ2o",
        "outputId": "24de0023-a7f4-42b8-a70b-38a91ec26c4c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.71652418e-02, -2.14226749e-02, -3.69014032e-02,  9.17513743e-02,\n",
              "       -1.07421661e-02,  4.66365442e-02, -1.84217598e-02,  1.65924802e-02,\n",
              "       -1.22968722e-02,  8.23152065e-03,  3.27579677e-03,  3.28216441e-02,\n",
              "       -1.43943066e-02, -6.44056546e-03,  4.68005566e-03, -1.52205955e-02,\n",
              "        2.90533975e-02,  2.26288419e-02, -2.85093486e-02, -7.26297647e-02,\n",
              "       -5.86174317e-02,  2.14552786e-02,  4.49853763e-02,  7.51551390e-02,\n",
              "       -9.40291490e-03,  6.26153126e-02,  1.09860962e-02,  1.42451199e-02,\n",
              "       -8.72330647e-03,  4.64042500e-02, -4.78688218e-02, -4.83297789e-03,\n",
              "       -1.03868255e-02, -4.19501662e-02, -5.24999574e-02,  6.82094321e-02,\n",
              "       -5.42349741e-02, -5.39837265e-03, -4.61527966e-02,  4.22852933e-02,\n",
              "        3.40135992e-02, -1.45326378e-02,  2.34187171e-02, -1.49338553e-02,\n",
              "        4.72984537e-02,  3.89861651e-02, -1.95441060e-02,  3.26468647e-02,\n",
              "       -4.88797799e-02,  9.26305726e-03,  7.05186874e-02,  4.72084582e-02,\n",
              "        2.21766699e-02,  4.64807898e-02, -9.69932154e-02,  1.51591217e-02,\n",
              "        6.08548755e-03,  3.86114907e-03,  2.43247580e-02, -1.96755771e-02,\n",
              "        3.33704054e-02,  3.38380598e-02, -4.74430667e-03, -5.90540320e-02,\n",
              "       -1.71243458e-03,  9.27992612e-02, -1.04533266e-02, -2.88959555e-02,\n",
              "        2.08191015e-02,  9.67317075e-02,  6.67207241e-02,  7.62426257e-02,\n",
              "        1.74782169e-03,  2.07658531e-03, -1.81955863e-02,  4.55280207e-02,\n",
              "       -7.14628473e-02, -1.77442115e-02, -5.55112138e-02,  8.35447088e-02,\n",
              "        7.71423280e-02,  3.16116922e-02,  4.28386498e-03,  2.95720082e-02,\n",
              "        5.77182584e-02,  9.44182929e-03,  3.09709273e-02,  2.07091179e-02,\n",
              "        1.19701214e-02, -1.27841244e-02,  1.94323864e-02,  1.39188711e-02,\n",
              "        4.63138781e-02, -1.92109635e-03,  9.46068242e-02, -1.86541479e-03,\n",
              "       -2.58588493e-02, -2.65322253e-02, -2.77669095e-02,  5.34552410e-02,\n",
              "        2.69377623e-02, -5.80563806e-02, -1.16699450e-02,  3.41869816e-02,\n",
              "       -2.02150512e-02,  8.78650472e-02,  2.41626911e-02,  4.24906658e-03,\n",
              "       -3.00677698e-02, -1.78718362e-02, -1.73427397e-03, -8.76720157e-03,\n",
              "       -6.80878833e-02, -4.45001014e-02, -2.42025312e-02, -1.01080529e-01,\n",
              "       -3.11668776e-02, -4.02847901e-02, -7.68085495e-02,  1.39082009e-02,\n",
              "       -1.49950841e-02,  1.52841676e-02, -7.74892569e-02, -5.60683161e-02,\n",
              "       -2.66029350e-02, -1.06912248e-01, -5.52712679e-02,  7.40672201e-02,\n",
              "        3.76071781e-03, -3.38090882e-02, -2.42280457e-02, -8.25715885e-02,\n",
              "        3.43487747e-02,  8.68472634e-05, -1.14248291e-01,  2.92813778e-02,\n",
              "        1.33774271e-02, -2.42300052e-02,  6.08405937e-03,  1.18474692e-01,\n",
              "        3.08750123e-02,  4.22719382e-02,  4.85849045e-02,  5.72910495e-02,\n",
              "        1.99655201e-02, -1.52962022e-02,  4.35380684e-03, -6.39681378e-03,\n",
              "       -4.47917953e-02, -1.46187693e-02, -1.93671305e-02, -2.50646230e-02,\n",
              "       -5.84607162e-02,  6.63697794e-02,  4.06754725e-02, -5.47326431e-02,\n",
              "        2.38423585e-03,  4.42523807e-02,  1.64759140e-02, -3.04594766e-02,\n",
              "        1.04979724e-01,  2.94528194e-02, -3.16681936e-02,  8.34025741e-02,\n",
              "        6.17961399e-02, -1.34688169e-02, -2.84590963e-02, -7.20835850e-02,\n",
              "        5.67105552e-03, -5.88863995e-03, -5.13223819e-02,  3.43222246e-02,\n",
              "       -4.61341999e-02, -1.38992351e-03,  2.70721521e-02,  6.94664642e-02,\n",
              "        8.55608061e-02, -1.73890982e-02, -7.46101514e-02, -3.01024094e-02,\n",
              "       -9.10803825e-02, -5.72861657e-02, -6.47161081e-02,  2.41919365e-02,\n",
              "       -8.01742263e-03, -1.69787593e-02,  1.44500509e-02,  1.37035437e-02,\n",
              "        4.51037614e-03,  1.03416899e-02,  2.53961626e-02, -2.26701982e-02,\n",
              "        9.27313268e-02, -6.10341392e-02,  2.11146730e-03, -3.46916951e-02,\n",
              "        4.16182131e-02, -3.14076804e-02, -4.31525856e-02,  5.11416607e-02,\n",
              "        2.84966305e-02,  7.33192116e-02, -2.08645742e-02, -2.05942132e-02,\n",
              "        2.54515428e-02,  2.56982204e-02,  2.99694315e-02, -4.91666012e-02,\n",
              "       -1.32797193e-02,  3.74200791e-02,  2.06470061e-02, -6.58948033e-04,\n",
              "       -3.02020647e-02,  1.52749522e-02,  3.61053972e-04, -7.19102565e-03,\n",
              "       -7.70405605e-02,  5.03438190e-02, -4.58404869e-02,  2.71898881e-02,\n",
              "       -5.60119888e-03, -9.98641029e-02, -4.05901223e-02, -1.73468459e-02,\n",
              "       -2.94468198e-02, -5.34161702e-02, -2.61059850e-02, -1.94981857e-03,\n",
              "       -5.26598021e-02, -8.99355114e-03,  3.97294685e-02,  3.65278535e-02,\n",
              "       -1.80845335e-02, -8.65160525e-02, -3.26273888e-02,  8.36857501e-03,\n",
              "        1.74296629e-02,  4.96954545e-02, -9.21559930e-02,  2.97430181e-03,\n",
              "        1.98876485e-02,  2.05321889e-03, -1.37190716e-02,  4.48528677e-02,\n",
              "        6.02802075e-02,  7.92442784e-02,  3.34962830e-02,  9.06707421e-02,\n",
              "        7.29662925e-03,  4.28409614e-02, -2.07978617e-02,  4.77605797e-02,\n",
              "       -7.08391308e-05,  2.91046631e-02,  4.36879694e-02,  4.42388207e-02,\n",
              "       -1.42221863e-03, -2.37643858e-03,  4.93517099e-03,  1.07808307e-01,\n",
              "        6.10910766e-02, -2.08560172e-02,  2.02932712e-02, -6.19768873e-02,\n",
              "       -3.15881334e-02,  3.23432731e-04, -2.71387473e-02,  8.27359501e-03,\n",
              "       -6.40115663e-02, -2.49079033e-03, -3.11468374e-02, -6.54108673e-02,\n",
              "        5.14276233e-03,  1.90644059e-02,  8.04698393e-02, -1.25988470e-02,\n",
              "       -1.08505907e-02, -2.90352348e-02, -2.47324035e-02, -2.50309557e-02,\n",
              "        4.28696163e-02, -3.21229808e-02, -7.54252672e-02, -9.14921388e-02,\n",
              "       -7.61295706e-02, -1.69333238e-02, -2.68962532e-02,  8.29378963e-02,\n",
              "       -5.91394305e-02, -7.36671537e-02,  2.40776278e-02, -5.03061861e-02,\n",
              "        5.40711358e-02, -5.12632318e-02, -2.35552192e-02, -8.82556960e-02,\n",
              "        1.60590594e-03,  4.11888286e-02,  5.66200912e-03,  1.54308928e-02,\n",
              "        7.24300295e-02, -5.00140116e-02,  8.91470388e-02, -7.93656260e-02,\n",
              "        6.02934361e-02, -3.13523225e-02, -5.38020441e-03, -7.14906119e-03,\n",
              "        3.93287577e-02, -1.55037618e-03,  3.77800055e-02,  2.28404347e-02,\n",
              "        1.82885677e-02,  3.60336527e-02,  4.74462025e-02,  2.42534578e-02,\n",
              "       -4.50962372e-02,  4.94615212e-02, -2.87480187e-02,  1.22758308e-02,\n",
              "        6.25258014e-02, -2.04453468e-02,  1.95486546e-02,  1.63090918e-02,\n",
              "       -2.87040174e-02,  1.00978119e-02, -1.26024475e-02,  1.56414974e-02,\n",
              "        6.41459227e-02,  3.81928086e-02,  6.59289584e-02, -1.38135236e-02,\n",
              "       -1.73554383e-02,  9.83952507e-02,  5.11847399e-02,  3.30670103e-02,\n",
              "       -4.18189168e-02,  1.32481456e-02,  2.12714281e-02, -1.81636214e-02,\n",
              "        5.47896000e-03,  1.47600537e-02,  7.24944472e-02, -3.98397632e-02,\n",
              "        3.02406177e-02, -7.49227479e-02, -1.16230631e-02,  7.18680099e-02,\n",
              "        3.46821956e-02, -5.02614165e-03, -1.86779704e-02,  1.04528368e-02,\n",
              "       -7.68906772e-02, -3.62794138e-02, -4.94624935e-02,  7.62295648e-02,\n",
              "        3.16861644e-02, -1.90391000e-02,  2.61455961e-02,  2.02991497e-02,\n",
              "       -2.80942079e-02,  7.82251135e-02, -2.17106193e-02,  8.77867732e-03,\n",
              "       -3.36996280e-02,  4.09158226e-03,  7.40962625e-02,  4.44274470e-02,\n",
              "        5.36636589e-03, -8.09258223e-02,  1.95319746e-02, -3.17919180e-02,\n",
              "        6.79097846e-02,  4.77874242e-02,  3.46744396e-02,  7.08520859e-02,\n",
              "       -1.85274705e-02,  2.36676205e-02, -6.54487461e-02, -6.40109330e-02,\n",
              "        3.89027707e-02,  3.58386640e-03, -6.28291145e-02,  3.47860977e-02,\n",
              "       -1.17666097e-02, -2.18544882e-02, -2.43917350e-02, -4.52139154e-02,\n",
              "       -1.77082408e-03, -2.95307599e-02,  5.24160191e-02, -2.14996021e-02,\n",
              "       -3.61010283e-02, -6.67097792e-02, -6.76639602e-02, -5.37361950e-02,\n",
              "        2.08320580e-02, -9.26018041e-03, -1.01517849e-02,  4.28468473e-02,\n",
              "       -5.29465452e-02,  7.28353113e-02, -2.71648262e-02,  1.45297488e-02,\n",
              "       -4.98832092e-02,  5.29044261e-03,  6.44309744e-02, -6.53474256e-02,\n",
              "        9.10133310e-03, -1.42408805e-02, -4.75462712e-03, -2.64120623e-02,\n",
              "        8.31066817e-02, -1.45917328e-03,  4.65334691e-02, -4.06028610e-03,\n",
              "       -1.75112975e-03,  2.56304760e-02, -3.91134992e-02, -2.30626948e-02,\n",
              "        4.78563085e-02,  8.86250054e-04, -2.94300131e-02, -3.51708988e-03,\n",
              "       -1.85441691e-02, -6.22772519e-03,  4.03431952e-02,  1.08352499e-02,\n",
              "        7.81803429e-02, -7.45634660e-02, -1.72693674e-02,  1.80402007e-02,\n",
              "       -1.50014432e-02, -6.51457906e-02, -5.59818260e-02, -2.48144269e-02,\n",
              "       -1.32891256e-02,  2.23462135e-02,  9.06735938e-03, -3.13866585e-02,\n",
              "       -8.59012529e-02,  2.10043751e-02, -6.51899129e-02,  9.52003300e-02,\n",
              "       -8.68617520e-02,  2.27035657e-02, -4.02060896e-02,  3.02489623e-02,\n",
              "       -5.67882732e-02, -3.17782015e-02, -3.95602472e-02,  1.86127443e-02,\n",
              "        1.83867216e-02, -7.55732358e-02, -1.77232847e-02,  1.70455612e-02,\n",
              "        2.85846721e-02,  8.69785547e-02,  2.58358754e-02,  2.21930351e-02,\n",
              "       -5.11378683e-02,  9.06218030e-03,  5.09728212e-03,  3.96288112e-02,\n",
              "        8.82079527e-02, -6.14260416e-03, -5.75170517e-02, -2.42777597e-02,\n",
              "        1.05726020e-02, -6.88147172e-02,  2.95409150e-02, -2.93106819e-03,\n",
              "        2.88098603e-02, -5.27210273e-02, -9.19215381e-02,  7.11615337e-03,\n",
              "        7.92758912e-02,  1.31641189e-02,  5.54478727e-02,  3.81460274e-03,\n",
              "        4.02279012e-02, -1.16900625e-02, -1.73248127e-02, -1.08749988e-02,\n",
              "       -4.93909977e-03,  4.39072549e-02, -1.11912362e-01,  2.90232580e-02,\n",
              "       -1.07661877e-02, -3.05820070e-02,  3.21460031e-02, -3.47666047e-03,\n",
              "        3.12222745e-02, -5.72177321e-02,  5.53461947e-02, -6.34792671e-02,\n",
              "       -1.23266317e-02, -5.11319414e-02,  3.57259018e-03, -1.66666768e-02,\n",
              "       -3.09683867e-02,  2.47310940e-02,  1.23976469e-02,  1.68150421e-02,\n",
              "        2.36362382e-03,  7.56094009e-02,  4.82997335e-02,  4.14109565e-02,\n",
              "        1.30790398e-02, -6.68270001e-03,  2.04597805e-02, -6.34549111e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data=[v4],\n",
        "    limit=1,\n",
        "    output_fields=[\"id\" , \"person_name\"]\n",
        ")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8m3jGw_N63N",
        "outputId": "8c16abcf-e939-44b7-f17e-d642068237a2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 1, 'distance': 1.000000238418579, 'entity': {'person_name': 'jetha 1', 'id': 1}}]\"]\n"
          ]
        }
      ]
    }
  ]
}